{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SENTIMENT ANALYSIS Based on Supervised Learning\n",
    "\n",
    "\n",
    "## Objectives\n",
    "\n",
    "1. Train your own supervised sentiment classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Session Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: html.parser in c:\\personal\\anaconda3\\lib\\site-packages (0.2)\n",
      "Requirement already satisfied: ply in c:\\personal\\anaconda3\\lib\\site-packages (from html.parser) (3.11)\n",
      "Requirement already satisfied: pattern3 in c:\\personal\\anaconda3\\lib\\site-packages (3.0.0)\n",
      "Requirement already satisfied: pdfminer3k in c:\\personal\\anaconda3\\lib\\site-packages (from pattern3) (1.3.4)\n",
      "Requirement already satisfied: simplejson in c:\\personal\\anaconda3\\lib\\site-packages (from pattern3) (3.17.5)\n",
      "Requirement already satisfied: cherrypy in c:\\personal\\anaconda3\\lib\\site-packages (from pattern3) (18.6.1)\n",
      "Requirement already satisfied: pdfminer.six in c:\\personal\\anaconda3\\lib\\site-packages (from pattern3) (20211012)\n",
      "Requirement already satisfied: feedparser in c:\\personal\\anaconda3\\lib\\site-packages (from pattern3) (6.0.8)\n",
      "Requirement already satisfied: docx in c:\\personal\\anaconda3\\lib\\site-packages (from pattern3) (0.2.4)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\personal\\anaconda3\\lib\\site-packages (from pattern3) (4.10.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\personal\\anaconda3\\lib\\site-packages (from beautifulsoup4->pattern3) (2.2.1)\n",
      "Requirement already satisfied: more-itertools in c:\\personal\\anaconda3\\lib\\site-packages (from cherrypy->pattern3) (8.8.0)\n",
      "Requirement already satisfied: pywin32>=227 in c:\\personal\\anaconda3\\lib\\site-packages (from cherrypy->pattern3) (228)\n",
      "Requirement already satisfied: cheroot>=8.2.1 in c:\\personal\\anaconda3\\lib\\site-packages (from cherrypy->pattern3) (8.5.2)\n",
      "Requirement already satisfied: zc.lockfile in c:\\personal\\anaconda3\\lib\\site-packages (from cherrypy->pattern3) (2.0)\n",
      "Requirement already satisfied: portend>=2.1.1 in c:\\personal\\anaconda3\\lib\\site-packages (from cherrypy->pattern3) (3.0.0)\n",
      "Requirement already satisfied: jaraco.collections in c:\\personal\\anaconda3\\lib\\site-packages (from cherrypy->pattern3) (3.4.0)\n",
      "Requirement already satisfied: six>=1.11.0 in c:\\personal\\anaconda3\\lib\\site-packages (from cheroot>=8.2.1->cherrypy->pattern3) (1.16.0)\n",
      "Requirement already satisfied: jaraco.functools in c:\\personal\\anaconda3\\lib\\site-packages (from cheroot>=8.2.1->cherrypy->pattern3) (3.4.0)\n",
      "Requirement already satisfied: tempora>=1.8 in c:\\personal\\anaconda3\\lib\\site-packages (from portend>=2.1.1->cherrypy->pattern3) (4.1.2)\n",
      "Requirement already satisfied: pytz in c:\\personal\\anaconda3\\lib\\site-packages (from tempora>=1.8->portend>=2.1.1->cherrypy->pattern3) (2021.3)\n",
      "Requirement already satisfied: lxml in c:\\personal\\anaconda3\\lib\\site-packages (from docx->pattern3) (4.6.3)\n",
      "Requirement already satisfied: Pillow>=2.0 in c:\\personal\\anaconda3\\lib\\site-packages (from docx->pattern3) (8.4.0)\n",
      "Requirement already satisfied: sgmllib3k in c:\\personal\\anaconda3\\lib\\site-packages (from feedparser->pattern3) (1.0.0)\n",
      "Requirement already satisfied: jaraco.text in c:\\personal\\anaconda3\\lib\\site-packages (from jaraco.collections->cherrypy->pattern3) (3.6.0)\n",
      "Requirement already satisfied: jaraco.classes in c:\\personal\\anaconda3\\lib\\site-packages (from jaraco.collections->cherrypy->pattern3) (3.2.1)\n",
      "Requirement already satisfied: importlib-resources in c:\\personal\\anaconda3\\lib\\site-packages (from jaraco.text->jaraco.collections->cherrypy->pattern3) (5.4.0)\n",
      "Requirement already satisfied: zipp>=3.1.0 in c:\\personal\\anaconda3\\lib\\site-packages (from importlib-resources->jaraco.text->jaraco.collections->cherrypy->pattern3) (3.6.0)\n",
      "Requirement already satisfied: chardet in c:\\personal\\anaconda3\\lib\\site-packages (from pdfminer.six->pattern3) (4.0.0)\n",
      "Requirement already satisfied: cryptography in c:\\personal\\anaconda3\\lib\\site-packages (from pdfminer.six->pattern3) (3.4.8)\n",
      "Requirement already satisfied: cffi>=1.12 in c:\\personal\\anaconda3\\lib\\site-packages (from cryptography->pdfminer.six->pattern3) (1.14.6)\n",
      "Requirement already satisfied: pycparser in c:\\personal\\anaconda3\\lib\\site-packages (from cffi>=1.12->cryptography->pdfminer.six->pattern3) (2.20)\n",
      "Requirement already satisfied: ply in c:\\personal\\anaconda3\\lib\\site-packages (from pdfminer3k->pattern3) (3.11)\n",
      "Requirement already satisfied: setuptools in c:\\personal\\anaconda3\\lib\\site-packages (from zc.lockfile->cherrypy->pattern3) (58.0.4)\n",
      "Requirement already satisfied: pyLDAvis in c:\\personal\\anaconda3\\lib\\site-packages (3.3.1)\n",
      "Requirement already satisfied: sklearn in c:\\personal\\anaconda3\\lib\\site-packages (from pyLDAvis) (0.0)\n",
      "Requirement already satisfied: future in c:\\personal\\anaconda3\\lib\\site-packages (from pyLDAvis) (0.18.2)\n",
      "Requirement already satisfied: jinja2 in c:\\personal\\anaconda3\\lib\\site-packages (from pyLDAvis) (2.11.3)\n",
      "Requirement already satisfied: funcy in c:\\personal\\anaconda3\\lib\\site-packages (from pyLDAvis) (1.16)\n",
      "Requirement already satisfied: setuptools in c:\\personal\\anaconda3\\lib\\site-packages (from pyLDAvis) (58.0.4)\n",
      "Requirement already satisfied: pandas>=1.2.0 in c:\\personal\\anaconda3\\lib\\site-packages (from pyLDAvis) (1.3.3)\n",
      "Requirement already satisfied: gensim in c:\\personal\\anaconda3\\lib\\site-packages (from pyLDAvis) (4.1.2)\n",
      "Requirement already satisfied: scipy in c:\\personal\\anaconda3\\lib\\site-packages (from pyLDAvis) (1.7.1)\n",
      "Requirement already satisfied: numpy>=1.20.0 in c:\\personal\\anaconda3\\lib\\site-packages (from pyLDAvis) (1.21.2)\n",
      "Requirement already satisfied: joblib in c:\\personal\\anaconda3\\lib\\site-packages (from pyLDAvis) (1.0.1)\n",
      "Requirement already satisfied: numexpr in c:\\personal\\anaconda3\\lib\\site-packages (from pyLDAvis) (2.7.3)\n",
      "Requirement already satisfied: scikit-learn in c:\\personal\\anaconda3\\lib\\site-packages (from pyLDAvis) (0.24.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\personal\\anaconda3\\lib\\site-packages (from pandas>=1.2.0->pyLDAvis) (2021.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\personal\\anaconda3\\lib\\site-packages (from pandas>=1.2.0->pyLDAvis) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\personal\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7.3->pandas>=1.2.0->pyLDAvis) (1.16.0)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\personal\\anaconda3\\lib\\site-packages (from gensim->pyLDAvis) (5.2.1)\n",
      "Requirement already satisfied: Cython==0.29.23 in c:\\personal\\anaconda3\\lib\\site-packages (from gensim->pyLDAvis) (0.29.23)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\personal\\anaconda3\\lib\\site-packages (from jinja2->pyLDAvis) (1.1.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\personal\\anaconda3\\lib\\site-packages (from scikit-learn->pyLDAvis) (2.2.0)\n",
      "Original:   <p>The circus dog in a plissé skirt jumped over Python who wasn't that large, just 3 feet long.</p>\n",
      "Processed:  ['<', 'p', '>', 'The', 'circus', 'dog', 'in', 'a', 'plissé', 'skirt', 'jumped', 'over', 'Python', 'who', 'was', \"n't\", 'that', 'large', ',', 'just', '3', 'feet', 'long.', '<', '/p', '>']\n",
      "Original:   <p>The circus dog in a plissé skirt jumped over Python who wasn't that large, just 3 feet long.</p>\n",
      "Processed:  <p>The circus dog in a plissé skirt jumped over Python who was not that large, just 3 feet long.</p>\n",
      "Original:   <p>The circus dog in a plissé skirt jumped over Python who wasn't that large, just 3 feet long.</p>\n",
      "Processed:  [('<', 'a'), ('p', 'n'), ('>', 'v'), ('the', None), ('circus', 'n'), ('dog', 'n'), ('in', None), ('a', None), ('plissé', 'n'), ('skirt', 'n'), ('jumped', 'v'), ('over', None), ('python', 'n'), ('who', None), ('was', 'v'), (\"n't\", 'r'), ('that', None), ('large', 'a'), (',', None), ('just', 'r'), ('3', None), ('feet', 'n'), ('long.', 'a'), ('<', 'n'), ('/p', 'n'), ('>', 'n')]\n",
      "Original:   <p>The circus dog in a plissé skirt jumped over Python who wasn't that large, just 3 feet long.</p>\n",
      "Processed:  < p > the circus dog in a plissé skirt jump over python who be n't that large , just 3 foot long. < /p >\n",
      "Original:   <p>The circus dog in a plissé skirt jumped over Python who wasn't that large, just 3 feet long.</p>\n",
      "Processed:    p   The circus dog in a plissé skirt jumped over Python who was n t that large   just 3 feet long     p  \n",
      "Original:   <p>The circus dog in a plissé skirt jumped over Python who wasn't that large, just 3 feet long.</p>\n",
      "Processed:  < p > The circus dog plissé skirt jumped Python n't large , 3 feet long. < /p >\n",
      "Original:   <p>The circus dog in a plissé skirt jumped over Python who wasn't that large, just 3 feet long.</p>\n",
      "Processed:  p The circus dog in a plissé skirt jumped over Python who was n't that large just feet long. /p\n",
      "Original:   <p>The circus dog in a plissé skirt jumped over Python who wasn't that large, just 3 feet long.</p>\n",
      "Processed:  The circus dog in a plissé skirt jumped over Python who wasn't that large, just 3 feet long.\n",
      "Original:   <p>The circus dog in a plissé skirt jumped over Python who wasn't that large, just 3 feet long.</p>\n",
      "Processed:  <p>The circus dog in a plisse skirt jumped over Python who wasn't that large, just 3 feet long.</p>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\LiGoudan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\LiGoudan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\LiGoudan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\LiGoudan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#packages needed\n",
    "\n",
    "#ignore warnings about future changes in functions as they take too much space\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "\n",
    "#text normalization function\n",
    "%run ./Text_Normalization_Function.ipynb\n",
    "\n",
    "#ignore warnings about future changes in functions as they take too much space\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Package for modeling\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import neural_network\n",
    "from sklearn import metrics\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "AmazonMucisInstrucment.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocess\n",
    "★Use Back Translation method to augment text data to increase sample size and fix inbalance problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions for data: (25028, 2)\n",
      "First 5 rows in dataset: \n",
      "                                           reviewText  overall\n",
      "0  Not much to write about here, but it does exac...        5\n",
      "1  The product does exactly as it should and is q...        5\n",
      "2  The primary job of this device is to block the...        5\n",
      "3  Nice windscreen protects my MXL mic and preven...        5\n",
      "4  This pop filter is great. It looks and perform...        5 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import in the Augmented data \n",
    "data = pd.read_csv('Musical_instruments_reviews_Augmented.csv')\n",
    "data = data.loc[:, ['reviewText', 'overall']]\n",
    "\n",
    "# Delete Null Samples\n",
    "float_ind = list()\n",
    "str_ind = list()\n",
    "for ind in data.index:\n",
    "    if type(data.loc[ind, 'reviewText']) == float:\n",
    "        float_ind.append(ind)\n",
    "    elif type(data.loc[ind, 'reviewText']) == str:\n",
    "        str_ind.append(ind)\n",
    "    else:\n",
    "        print(str(i) + ': ' + str(type(data.loc[ind, 'reviewText'])))\n",
    "\n",
    "# Delete blank samples\n",
    "data.drop(labels=None, axis=0, index=float_ind, columns=None, inplace=True)\n",
    "\n",
    "print(\"Dimensions for data:\", data.shape)\n",
    "print(\"First 5 rows in dataset: \\n\", data.head(),\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training your Own Sentiment Classifier (Supervised Machine Learning)\n",
    "\n",
    "Given that we have **labels** in the data, we can take advantage of them and train our own **sentiment classifier**. Let's do it and see if the performance of the custom classifier would be better than of the lexicon-based model above.\n",
    "\n",
    "Start by vectorizing the normalized training dataset. Let's use TF-IDF approach and use a mix of **uni-grams** and **bi-grams** as features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([3524.,    0., 3774.,    0.,    0., 6967.,    0., 3831.,    0.,\n",
       "        6932.]),\n",
       " array([1. , 1.4, 1.8, 2.2, 2.6, 3. , 3.4, 3.8, 4.2, 4.6, 5. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Descriptive Analysis\n",
    "plt.figure()\n",
    "plt.title('Total Rating')\n",
    "plt.hist(data['overall'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 13, 14, 17, 18, 19, 21, 23, 24, 26, 27, 29, 30, 31, 33, 34, 38, 40, 41, 42, 43, 44, 47, 48, 49, 51, 54, 55, 56, 57, 60, 61, 62, 63, 64, 65, 66, 68, 69, 70, 72, 75, 78, 80, 81, 82, 83, 84, 85, 86, 87, 90, 91, 92, 94, 95, 96, 99, 100, 101, 102, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 119, 120, 121, 124, 125, 126, 127, 129, 130, 132, 133, 134, 135, 136, 137, 139, 140, 141, 145, 146, 147, 149, 150, 152, 153, 154, 155, 156, 158, 159, 161, 162, 163, 165, 166, 167, 168, 169, 171, 176, 182, 183, 187, 188, 191, 192, 193, 194, 195, 196, 197, 198, 201, 203, 204, 205, 209, 210, 211, 212, 213, 217, 220, 221, 226, 227, 229, 233, 235, 236, 237, 238, 239, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 260, 263, 264, 265, 267, 268, 271, 272, 273, 274, 275, 277, 278, 279, 280, 282, 284, 285, 288, 289, 290, 292, 293, 294, 296, 297, 298, 299, 301, 304, 305, 308, 309, 310, 311, 312, 314, 315, 317, 318, 319, 320, 321, 322, 323, 326, 327, 328, 329, 333, 338, 339, 340, 344, 346, 348, 349, 350, 352, 355, 356, 357, 358, 359, 360, 362, 363, 364, 365, 368, 370, 371, 372, 373, 374, 375, 377, 378, 379, 380, 382, 384, 385, 387, 388, 390, 391, 392, 393, 394, 395, 396, 399, 402, 403, 405, 406, 407, 410, 411, 415, 417, 420, 421, 422, 426, 427, 428, 429, 432, 433, 435, 436, 438, 439, 442, 443, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 459, 460, 461, 462, 464, 465, 466, 467, 468, 469, 470, 472, 473, 474, 476, 478, 479, 480, 481, 486, 487, 489, 491, 492, 493, 495, 496, 497, 498, 500, 502, 503, 504, 505, 507, 508, 510, 511, 512, 513, 518, 519, 521, 522, 523, 524, 525, 526, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 540, 543, 548, 551, 552, 555, 556, 558, 559, 560, 562, 563, 564, 565, 566, 568, 569, 570, 571, 573, 574, 575, 576, 577, 578, 580, 582, 583, 584, 587, 589, 591, 592, 597, 598, 600, 602, 605, 609, 610, 612, 613, 616, 623, 624, 625, 626, 627, 629, 631, 632, 634, 636, 637, 638, 639, 640, 641, 643, 644, 645, 647, 648, 649, 652, 653, 654, 655, 656, 657, 659, 661, 662, 664, 665, 666, 667, 668, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 683, 684, 685, 686, 689, 690, 694, 695, 697, 698, 699, 700, 701, 702, 704, 705, 706, 707, 708, 710, 711, 716, 717, 718, 719, 720, 721, 722, 723, 725, 726, 727, 728, 730, 732, 733, 734, 736, 737, 738, 739, 740, 742, 743, 744, 746, 747, 748, 749, 750, 751, 753, 754, 756, 757, 758, 760, 761, 762, 763, 764, 766, 767, 768, 769, 770, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 785, 786, 787, 789, 790, 791, 792, 793, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 814, 815, 816, 817, 818, 822, 823, 826, 827, 828, 831, 834, 835, 836, 837, 838, 839, 841, 843, 844, 846, 847, 848, 849, 850, 851, 852, 854, 855, 856, 857, 858, 859, 861, 863, 864, 865, 866, 868, 869, 870, 871, 872, 873, 881, 884, 888, 889, 890, 891, 893, 894, 898, 900, 901, 902, 903, 904, 906, 907, 908, 910, 911, 912, 913, 914, 916, 918, 919, 921, 922, 923, 924, 933, 937, 938, 939, 940, 941, 942, 943, 944, 945, 946, 947, 948, 952, 954, 955, 959, 963, 964, 965, 967, 972, 974, 975, 976, 978, 979, 980, 983, 985, 986, 987, 988, 989, 990, 991, 992, 994, 995, 997, 999, 1000, 1001, 1002, 1004, 1006, 1008, 1009, 1010, 1012, 1013, 1014, 1015, 1016, 1017, 1018, 1019, 1021, 1023, 1024, 1025, 1026, 1028, 1029, 1030, 1031, 1032, 1034, 1036, 1037, 1039, 1040, 1041, 1043, 1046, 1047, 1048, 1049, 1051, 1052, 1054, 1055, 1057, 1059, 1060, 1061, 1062, 1063, 1064, 1065, 1066, 1068, 1070, 1071, 1073, 1074, 1075, 1076, 1077, 1078, 1079, 1080, 1083, 1084, 1085, 1087, 1088, 1090, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1099, 1100, 1101, 1102, 1103, 1105, 1107, 1108, 1109, 1110, 1111, 1112, 1113, 1115, 1116, 1120, 1121, 1123, 1126, 1127, 1129, 1130, 1131, 1133, 1134, 1135, 1136, 1138, 1140, 1141, 1144, 1145, 1147, 1148, 1149, 1150, 1151, 1152, 1153, 1154, 1155, 1156, 1158, 1159, 1162, 1163, 1164, 1165, 1167, 1168, 1169, 1172, 1176, 1180, 1181, 1182, 1184, 1186, 1187, 1188, 1189, 1190, 1191, 1192, 1193, 1194, 1195, 1197, 1198, 1199, 1201, 1202, 1203, 1205, 1206, 1207, 1210, 1212, 1213, 1214, 1215, 1216, 1217, 1218, 1219, 1220, 1221, 1222, 1223, 1224, 1225, 1226, 1228, 1229, 1231, 1233, 1237, 1239, 1240, 1243, 1246, 1247, 1248, 1249, 1250, 1252, 1253, 1255, 1256, 1257, 1258, 1259, 1260, 1261, 1263, 1264, 1265, 1267, 1268, 1269, 1270, 1271, 1272, 1273, 1274, 1275, 1276, 1277, 1278, 1280, 1281, 1282, 1284, 1285, 1286, 1287, 1288, 1290, 1291, 1294, 1295, 1296, 1297, 1298, 1299, 1300, 1301, 1305, 1307, 1308, 1310, 1312, 1313, 1314, 1315, 1318, 1319, 1320, 1323, 1324, 1326, 1327, 1328, 1329, 1331, 1332, 1333, 1336, 1339, 1340, 1341, 1342, 1343, 1344, 1346, 1347, 1348, 1350, 1351, 1353, 1354, 1355, 1356, 1357, 1361, 1362, 1365, 1366, 1367, 1369, 1370, 1371, 1372, 1375, 1376, 1377, 1379, 1381, 1382, 1383, 1384, 1385, 1386, 1387, 1388, 1390, 1391, 1392, 1393, 1399, 1400, 1401, 1403, 1406, 1407, 1409, 1412, 1416, 1417, 1418, 1419, 1421, 1422, 1423, 1425, 1427, 1428, 1430, 1432, 1433, 1434, 1435, 1436, 1437, 1439, 1440, 1441, 1442, 1443, 1445, 1446, 1447, 1448, 1449, 1450, 1451, 1452, 1453, 1456, 1457, 1458, 1459, 1460, 1462, 1463, 1464, 1465, 1466, 1467, 1469, 1470, 1471, 1473, 1475, 1478, 1479, 1480, 1481, 1482, 1484, 1485, 1486, 1489, 1490, 1493, 1496, 1497, 1498, 1499, 1501, 1502, 1503, 1504, 1505, 1506, 1509, 1510, 1513, 1514, 1515, 1516, 1518, 1519, 1520, 1521, 1522, 1523, 1525, 1526, 1528, 1529, 1530, 1532, 1533, 1534, 1535, 1536, 1537, 1538, 1539, 1541, 1542, 1543, 1544, 1545, 1546, 1547, 1548, 1549, 1552, 1554, 1555, 1556, 1558, 1560, 1561, 1565, 1566, 1569, 1572, 1573, 1574, 1575, 1576, 1577, 1580, 1583, 1584, 1590, 1591, 1592, 1594, 1596, 1597, 1598, 1600, 1601, 1603, 1605, 1606, 1609, 1610, 1613, 1614, 1616, 1617, 1618, 1620, 1621, 1622, 1623, 1625, 1626, 1627, 1631, 1634, 1635, 1636, 1637, 1638, 1639, 1641, 1644, 1645, 1646, 1647, 1648, 1649, 1650, 1653, 1654, 1656, 1658, 1659, 1660, 1662, 1664, 1665, 1666, 1667, 1669, 1670, 1671, 1672, 1673, 1675, 1677, 1678, 1681, 1682, 1683, 1685, 1686, 1687, 1688, 1689, 1690, 1691, 1692, 1693, 1694, 1695, 1696, 1697, 1698, 1700, 1701, 1702, 1703, 1704, 1705, 1706, 1707, 1709, 1710, 1711, 1712, 1713, 1714, 1716, 1717, 1718, 1719, 1720, 1721, 1722, 1723, 1725, 1726, 1727, 1728, 1730, 1731, 1732, 1734, 1735, 1736, 1737, 1740, 1742, 1743, 1744, 1746, 1749, 1750, 1751, 1752, 1753, 1754, 1755, 1757, 1758, 1759, 1760, 1761, 1764, 1766, 1767, 1768, 1769, 1770, 1772, 1773, 1774, 1775, 1776, 1777, 1778, 1779, 1781, 1782, 1784, 1787, 1789, 1790, 1794, 1795, 1798, 1800, 1801, 1802, 1805, 1806, 1807, 1809, 1810, 1811, 1812, 1814, 1815, 1816, 1818, 1822, 1823, 1824, 1825, 1826, 1828, 1829, 1832, 1835, 1837, 1838, 1840, 1841, 1842, 1844, 1845, 1847, 1848, 1851, 1852, 1853, 1856, 1857, 1859, 1860, 1861, 1862, 1864, 1865, 1866, 1867, 1871, 1874, 1878, 1881, 1882, 1883, 1884, 1885, 1886, 1887, 1888, 1891, 1892, 1893, 1899, 1900, 1901, 1902, 1903, 1905, 1906, 1907, 1908, 1909, 1910, 1911, 1912, 1913, 1914, 1915, 1916, 1917, 1919, 1920, 1921, 1922, 1923, 1924, 1926, 1927, 1928, 1930, 1931, 1932, 1933, 1934, 1935, 1936, 1937, 1938, 1939, 1940, 1942, 1943, 1944, 1946, 1947, 1948, 1949, 1951, 1953, 1956, 1957, 1958, 1960, 1961, 1963, 1966, 1968, 1969, 1970, 1971, 1972, 1974, 1975, 1976, 1977, 1978, 1980, 1981, 1982, 1983, 1985, 1986, 1987, 1988, 1990, 1991, 1992, 1993, 1997, 2002, 2003, 2004, 2005, 2007, 2010, 2011, 2012, 2013, 2014, 2017, 2018, 2021, 2023, 2024, 2025, 2028, 2029, 2030, 2031, 2032, 2033, 2034, 2035, 2036, 2037, 2041, 2042, 2043, 2044, 2045, 2046, 2047, 2048, 2049, 2050, 2051, 2052, 2053, 2055, 2056, 2058, 2059, 2060, 2061, 2062, 2063, 2064, 2065, 2067, 2069, 2070, 2072, 2073, 2074, 2076, 2077, 2078, 2079, 2080, 2082, 2083, 2085, 2086, 2087, 2088, 2091, 2092, 2093, 2096, 2098, 2100, 2102, 2103, 2104, 2106, 2107, 2108, 2109, 2110, 2113, 2114, 2115, 2116, 2117, 2118, 2119, 2120, 2121, 2122, 2124, 2126, 2127, 2128, 2129, 2133, 2135, 2137, 2140, 2141, 2143, 2145, 2146, 2148, 2149, 2150, 2151, 2152, 2156, 2157, 2158, 2159, 2160, 2161, 2163, 2164, 2165, 2167, 2168, 2169, 2170, 2171, 2172, 2173, 2174, 2175, 2176, 2177, 2178, 2179, 2180, 2181, 2182, 2184, 2185, 2186, 2189, 2190, 2191, 2192, 2194, 2195, 2196, 2197, 2198, 2199, 2201, 2202, 2204, 2205, 2206, 2207, 2208, 2209, 2211, 2212, 2213, 2214, 2215, 2216, 2217, 2218, 2220, 2222, 2223, 2224, 2227, 2228, 2229, 2230, 2231, 2233, 2237, 2239, 2242, 2243, 2244, 2245, 2246, 2247, 2249, 2253, 2254, 2255, 2258, 2259, 2260, 2261, 2262, 2264, 2265, 2266, 2270, 2271, 2272, 2273, 2274, 2275, 2276, 2277, 2278, 2280, 2281, 2282, 2283, 2284, 2286, 2287, 2289, 2290, 2291, 2292, 2293, 2294, 2295, 2296, 2297, 2298, 2299, 2300, 2301, 2302, 2303, 2304, 2306, 2307, 2309, 2310, 2311, 2316, 2317, 2321, 2323, 2324, 2326, 2328, 2329, 2331, 2333, 2334, 2337, 2338, 2339, 2341, 2342, 2343, 2344, 2345, 2346, 2347, 2348, 2349, 2350, 2351, 2352, 2353, 2354, 2355, 2356, 2357, 2359, 2360, 2361, 2364, 2366, 2367, 2368, 2370, 2371, 2373, 2374, 2375, 2376, 2378, 2379, 2380, 2382, 2384, 2385, 2386, 2388, 2389, 2390, 2391, 2392, 2394, 2398, 2402, 2404, 2405, 2406, 2407, 2409, 2410, 2411, 2412, 2414, 2415, 2416, 2417, 2418, 2419, 2420, 2422, 2426, 2427, 2428, 2429, 2430, 2431, 2432, 2433, 2434, 2435, 2437, 2438, 2439, 2440, 2441, 2443, 2444, 2445, 2447, 2448, 2449, 2451, 2452, 2453, 2454, 2455, 2456, 2458, 2459, 2462, 2464, 2465, 2468, 2469, 2470, 2471, 2472, 2475, 2477, 2478, 2480, 2481, 2482, 2483, 2485, 2486, 2487, 2488, 2489, 2490, 2492, 2493, 2494, 2495, 2496, 2497, 2498, 2499, 2500, 2501, 2503, 2504, 2505, 2507, 2509, 2510, 2512, 2513, 2515, 2516, 2517, 2519, 2520, 2521, 2523, 2524, 2525, 2530, 2533, 2535, 2536, 2537, 2538, 2539, 2540, 2541, 2542, 2543, 2544, 2545, 2546, 2547, 2548, 2550, 2552, 2553, 2554, 2555, 2557, 2559, 2561, 2564, 2565, 2568, 2569, 2570, 2572, 2573, 2575, 2577, 2578, 2579, 2584, 2585, 2586, 2588, 2589, 2590, 2592, 2593, 2595, 2597, 2599, 2600, 2602, 2603, 2604, 2608, 2609, 2611, 2612, 2614, 2615, 2616, 2618, 2619, 2621, 2623, 2625, 2626, 2627, 2629, 2631, 2632, 2634, 2635, 2636, 2637, 2638, 2639, 2642, 2643, 2645, 2646, 2647, 2648, 2651, 2652, 2653, 2655, 2656, 2657, 2659, 2660, 2661, 2663, 2664, 2666, 2667, 2668, 2670, 2672, 2673, 2674, 2675, 2678, 2679, 2683, 2684, 2685, 2686, 2687, 2688, 2690, 2691, 2692, 2693, 2694, 2695, 2697, 2698, 2699, 2700, 2702, 2703, 2704, 2705, 2706, 2707, 2708, 2709, 2711, 2713, 2715, 2716, 2718, 2719, 2721, 2722, 2724, 2726, 2727, 2729, 2732, 2733, 2734, 2735, 2736, 2738, 2739, 2741, 2742, 2744, 2745, 2746, 2747, 2748, 2749, 2750, 2752, 2753, 2754, 2756, 2757, 2758, 2759, 2760, 2761, 2762, 2763, 2764, 2765, 2767, 2768, 2769, 2770, 2773, 2776, 2779, 2780, 2782, 2783, 2787, 2788, 2789, 2790, 2791, 2792, 2793, 2794, 2796, 2798, 2799, 2800, 2801, 2803, 2805, 2806, 2807, 2808, 2809, 2810, 2813, 2816, 2817, 2818, 2819, 2821, 2822, 2823, 2824, 2827, 2828, 2829, 2832, 2833, 2835, 2836, 2837, 2838, 2839, 2840, 2841, 2842, 2843, 2844, 2846, 2848, 2849, 2850, 2851, 2852, 2854, 2855, 2856, 2857, 2859, 2860, 2861, 2862, 2863, 2865, 2866, 2867, 2868, 2869, 2870, 2871, 2874, 2875, 2876, 2877, 2879, 2880, 2882, 2885, 2886, 2887, 2888, 2889, 2890, 2891, 2892, 2893, 2894, 2895, 2896, 2897, 2898, 2900, 2902, 2904, 2905, 2906, 2907, 2908, 2910, 2913, 2914, 2916, 2917, 2918, 2919, 2920, 2921, 2923, 2932, 2933, 2934, 2935, 2936, 2937, 2938, 2939, 2941, 2943, 2945, 2946, 2947, 2948, 2950, 2951, 2952, 2953, 2955, 2956, 2957, 2958, 2960, 2963, 2965, 2966, 2967, 2968, 2969, 2971, 2972, 2974, 2977, 2978, 2979, 2980, 2981, 2982, 2984, 2986, 2987, 2988, 2991, 2992, 2994, 2998, 2999, 3000, 3003, 3005, 3006, 3007, 3008, 3009, 3011, 3012, 3013, 3019, 3021, 3024, 3026, 3027, 3030, 3032, 3034, 3035, 3036, 3037, 3038, 3040, 3042, 3044, 3045, 3046, 3047, 3048, 3049, 3051, 3052, 3053, 3054, 3056, 3057, 3058, 3059, 3060, 3061, 3062, 3063, 3065, 3066, 3068, 3070, 3071, 3073, 3091, 3092, 3093, 3094, 3096, 3098, 3099, 3100, 3101, 3102, 3104, 3105, 3107, 3108, 3109, 3110, 3111, 3112, 3113, 3114, 3115, 3116, 3117, 3119, 3120, 3121, 3122, 3123, 3124, 3125, 3126, 3127, 3128, 3130, 3131, 3134, 3135, 3136, 3137, 3140, 3141, 3142, 3143, 3144, 3146, 3147, 3149, 3151, 3152, 3154, 3155, 3157, 3158, 3159, 3161, 3163, 3164, 3165, 3166, 3168, 3169, 3170, 3171, 3172, 3173, 3174, 3176, 3178, 3179, 3180, 3181, 3182, 3185, 3186, 3187, 3188, 3189, 3190, 3191, 3193, 3194, 3195, 3196, 3198, 3201, 3202, 3203, 3204, 3205, 3206, 3207, 3209, 3211, 3212, 3215, 3216, 3217, 3218, 3219, 3220, 3222, 3223, 3224, 3225, 3226, 3229, 3231, 3232, 3236, 3237, 3239, 3240, 3241, 3242, 3244, 3248, 3250, 3251, 3253, 3255, 3256, 3257, 3261, 3263, 3264, 3267, 3268, 3269, 3270, 3271, 3272, 3273, 3274, 3275, 3276, 3277, 3278, 3280, 3281, 3284, 3285, 3286, 3287, 3288, 3289, 3290, 3291, 3292, 3293, 3294, 3295, 3297, 3298, 3299, 3300, 3301, 3302, 3303, 3304, 3305, 3306, 3307, 3309, 3311, 3312, 3313, 3314, 3316, 3318, 3319, 3320, 3321, 3322, 3323, 3324, 3326, 3327, 3328, 3332, 3333, 3334, 3335, 3337, 3338, 3339, 3340, 3341, 3343, 3344, 3345, 3347, 3349, 3351, 3353, 3356, 3357, 3358, 3359, 3360, 3361, 3362, 3364, 3365, 3366, 3367, 3368, 3369, 3370, 3372, 3376, 3377, 3378, 3380, 3381, 3383, 3384, 3386, 3387, 3390, 3392, 3393, 3395, 3398, 3399, 3400, 3401, 3402, 3403, 3405, 3406, 3408, 3409, 3412, 3413, 3416, 3418, 3419, 3420, 3421, 3422, 3423, 3426, 3427, 3429, 3431, 3432, 3433, 3434, 3441, 3442, 3443, 3444, 3445, 3446, 3447, 3448, 3451, 3452, 3455, 3456, 3457, 3458, 3460, 3461, 3463, 3464, 3465, 3466, 3467, 3468, 3469, 3470, 3471, 3472, 3473, 3474, 3476, 3477, 3478, 3479, 3482, 3483, 3484, 3485, 3487, 3489, 3490, 3492, 3493, 3494, 3495, 3496, 3497, 3498, 3500, 3501, 3502, 3504, 3507, 3511, 3514, 3515, 3517, 3521, 3523, 3526, 3528, 3529, 3532, 3534, 3535, 3536, 3539, 3540, 3541, 3542, 3543, 3545, 3546, 3548, 3551, 3552, 3553, 3554, 3556, 3557, 3560, 3562, 3563, 3564, 3565, 3566, 3569, 3573, 3574, 3575, 3576, 3577, 3579, 3580, 3582, 3583, 3584, 3585, 3586, 3587, 3588, 3589, 3590, 3591, 3592, 3593, 3594, 3598, 3599, 3600, 3601, 3602, 3603, 3604, 3605, 3606, 3607, 3609, 3612, 3613, 3614, 3615, 3616, 3617, 3619, 3620, 3621, 3622, 3624, 3625, 3626, 3627, 3628, 3630, 3632, 3637, 3638, 3639, 3640, 3642, 3643, 3645, 3647, 3648, 3649, 3650, 3651, 3652, 3655, 3657, 3658, 3659, 3660, 3661, 3663, 3664, 3665, 3667, 3669, 3670, 3671, 3672, 3673, 3674, 3675, 3679, 3683, 3685, 3686, 3687, 3688, 3689, 3690, 3692, 3694, 3695, 3698, 3699, 3700, 3701, 3702, 3703, 3704, 3705, 3710, 3711, 3712, 3713, 3714, 3715, 3716, 3718, 3719, 3721, 3722, 3723, 3724, 3725, 3726, 3727, 3728, 3729, 3732, 3733, 3734, 3739, 3740, 3741, 3744, 3745, 3749, 3750, 3751, 3752, 3753, 3756, 3757, 3759, 3760, 3762, 3763, 3764, 3766, 3767, 3768, 3769, 3770, 3772, 3773, 3775, 3776, 3777, 3778, 3779, 3780, 3781, 3782, 3783, 3784, 3785, 3786, 3787, 3794, 3795, 3796, 3798, 3799, 3800, 3801, 3802, 3803, 3804, 3806, 3807, 3808, 3809, 3810, 3811, 3812, 3813, 3814, 3815, 3816, 3817, 3818, 3820, 3821, 3822, 3823, 3824, 3825, 3826, 3827, 3828, 3829, 3831, 3832, 3834, 3835, 3836, 3837, 3838, 3839, 3840, 3841, 3842, 3843, 3844, 3845, 3846, 3847, 3849, 3850, 3851, 3852, 3853, 3855, 3856, 3857, 3858, 3859, 3861, 3862, 3863, 3864, 3865, 3866, 3867, 3868, 3870, 3871, 3872, 3873, 3874, 3875, 3876, 3877, 3878, 3879, 3881, 3882, 3883, 3884, 3885, 3886, 3887, 3888, 3890, 3893, 3895, 3896, 3897, 3899, 3900, 3903, 3904, 3905, 3906, 3907, 3910, 3912, 3913, 3914, 3915, 3923, 3925, 3926, 3927, 3928, 3930, 3931, 3932, 3934, 3936, 3937, 3939, 3942, 3943, 3947, 3956, 3957, 3958, 3959, 3960, 3961, 3962, 3963, 3964, 3965, 3966, 3967, 3968, 3971, 3973, 3974, 3975, 3976, 3977, 3978, 3979, 3980, 3982, 3986, 3988, 3989, 3991, 3992, 3993, 3996, 4001, 4003, 4004, 4005, 4008, 4009, 4010, 4011, 4012, 4013, 4014, 4015, 4016, 4018, 4020, 4023, 4024, 4025, 4028, 4029, 4030, 4031, 4032, 4034, 4035, 4036, 4037, 4038, 4041, 4042, 4043, 4045, 4047, 4048, 4049, 4050, 4051, 4052, 4053, 4054, 4055, 4056, 4058, 4059, 4060, 4061, 4062, 4063, 4064, 4065, 4066, 4067, 4069, 4070, 4071, 4072, 4073, 4074, 4075, 4076, 4077, 4079, 4080, 4083, 4085, 4087, 4089, 4090, 4091, 4092, 4093, 4094, 4096, 4098, 4099, 4100, 4101, 4106, 4114, 4116, 4117, 4118, 4119, 4120, 4122, 4123, 4124, 4125, 4127, 4128, 4129, 4130, 4132, 4133, 4134, 4135, 4136, 4137, 4138, 4142, 4143, 4144, 4145, 4146, 4147, 4149, 4150, 4151, 4152, 4154, 4155, 4156, 4158, 4160, 4162, 4163, 4164, 4168, 4169, 4170, 4171, 4174, 4176, 4177, 4178, 4181, 4182, 4183, 4184, 4185, 4186, 4188, 4189, 4190, 4191, 4193, 4195, 4196, 4197, 4198, 4199, 4200, 4202, 4204, 4205, 4206, 4208, 4210, 4211, 4212, 4216, 4217, 4218, 4219, 4222, 4223, 4225, 4226, 4227, 4229, 4230, 4231, 4232, 4235, 4236, 4237, 4238, 4239, 4240, 4243, 4244, 4246, 4247, 4248, 4251, 4252, 4254, 4257, 4259, 4260, 4261, 4265, 4267, 4269, 4270, 4271, 4272, 4275, 4277, 4278, 4281, 4285, 4287, 4288, 4290, 4291, 4292, 4293, 4294, 4296, 4297, 4299, 4301, 4302, 4303, 4306, 4307, 4308, 4309, 4310, 4311, 4312, 4314, 4315, 4317, 4319, 4320, 4321, 4322, 4324, 4327, 4329, 4330, 4331, 4334, 4336, 4340, 4341, 4342, 4346, 4347, 4349, 4350, 4352, 4353, 4354, 4355, 4356, 4358, 4359, 4361, 4362, 4363, 4364, 4366, 4374, 4375, 4377, 4378, 4379, 4380, 4381, 4383, 4385, 4387, 4390, 4391, 4392, 4393, 4394, 4395, 4396, 4397, 4398, 4399, 4400, 4402, 4404, 4406, 4407, 4408, 4409, 4410, 4412, 4413, 4414, 4417, 4418, 4422, 4424, 4425, 4426, 4427, 4428, 4429, 4432, 4434, 4435, 4436, 4440, 4441, 4442, 4445, 4446, 4448, 4449, 4450, 4451, 4452, 4455, 4456, 4457, 4458, 4460, 4461, 4462, 4465, 4468, 4469, 4470, 4472, 4473, 4474, 4476, 4480, 4483, 4484, 4485, 4486, 4487, 4489, 4490, 4492, 4493, 4494, 4495, 4496, 4497, 4498, 4499, 4500, 4501, 4503, 4504, 4505, 4506, 4507, 4511, 4512, 4513, 4515, 4516, 4517, 4518, 4519, 4520, 4522, 4523, 4524, 4525, 4526, 4527, 4528, 4529, 4530, 4531, 4532, 4534, 4535, 4536, 4537, 4538, 4540, 4541, 4542, 4544, 4545, 4546, 4547, 4548, 4549, 4553, 4554, 4555, 4556, 4557, 4559, 4560, 4561, 4563, 4565, 4567, 4568, 4571, 4572, 4573, 4574, 4576, 4578, 4579, 4583, 4584, 4585, 4586, 4587, 4588, 4589, 4590, 4591, 4592, 4593, 4594, 4595, 4596, 4599, 4600, 4602, 4605, 4608, 4610, 4613, 4614, 4616, 4617, 4619, 4620, 4623, 4625, 4626, 4627, 4628, 4629, 4630, 4631, 4634, 4635, 4637, 4638, 4639, 4640, 4641, 4643, 4644, 4645, 4646, 4648, 4649, 4650, 4651, 4652, 4654, 4655, 4658, 4659, 4660, 4661, 4662, 4663, 4664, 4665, 4666, 4668, 4669, 4670, 4671, 4672, 4674, 4675, 4677, 4679, 4680, 4681, 4682, 4686, 4687, 4688, 4690, 4691, 4692, 4693, 4695, 4697, 4701, 4703, 4704, 4705, 4707, 4711, 4714, 4715, 4718, 4720, 4723, 4726, 4727, 4728, 4729, 4730, 4731, 4732, 4735, 4736, 4739, 4740, 4741, 4742, 4745, 4746, 4747, 4749, 4750, 4755, 4757, 4758, 4759, 4761, 4762, 4763, 4764, 4765, 4766, 4767, 4772, 4774, 4775, 4777, 4779, 4780, 4783, 4784, 4785, 4786, 4787, 4788, 4790, 4791, 4792, 4793, 4796, 4799, 4802, 4803, 4804, 4806, 4807, 4808, 4809, 4810, 4811, 4813, 4814, 4815, 4816, 4817, 4819, 4821, 4824, 4825, 4826, 4830, 4831, 4832, 4834, 4838, 4840, 4841, 4843, 4844, 4845, 4846, 4847, 4848, 4849, 4850, 4851, 4852, 4853, 4854, 4855, 4856, 4857, 4858, 4859, 4863, 4864, 4865, 4866, 4867, 4869, 4875, 4876, 4878, 4879, 4881, 4883, 4885, 4886, 4887, 4888, 4889, 4890, 4891, 4892, 4893, 4894, 4895, 4896, 4898, 4899, 4900, 4902, 4903, 4904, 4905, 4909, 4911, 4914, 4916, 4919, 4924, 4925, 4926, 4930, 4932, 4933, 4934, 4935, 4936, 4937, 4938, 4940, 4941, 4942, 4944, 4945, 4949, 4950, 4951, 4952, 4953, 4955, 4956, 4960, 4962, 4963, 4964, 4966, 4968, 4969, 4972, 4973, 4974, 4975, 4976, 4977, 4978, 4979, 4980, 4981, 4983, 4986, 4987, 4988, 4989, 4990, 4991, 4992, 4993, 4994, 4995, 4996, 4997, 4998, 4999, 5001, 5002, 5003, 5004, 5005, 5006, 5007, 5008, 5009, 5010, 5011, 5012, 5013, 5014, 5015, 5016, 5018, 5019, 5022, 5023, 5024, 5025, 5026, 5027, 5028, 5030, 5034, 5036, 5037, 5038, 5039, 5040, 5041, 5042, 5043, 5044, 5045, 5049, 5051, 5053, 5054, 5057, 5059, 5060, 5061, 5062, 5063, 5064, 5066, 5067, 5069, 5070, 5071, 5074, 5075, 5076, 5077, 5078, 5079, 5080, 5081, 5082, 5083, 5084, 5085, 5087, 5088, 5089, 5090, 5091, 5092, 5093, 5094, 5097, 5098, 5099, 5100, 5102, 5103, 5105, 5107, 5108, 5109, 5110, 5111, 5112, 5113, 5114, 5115, 5116, 5117, 5118, 5119, 5122, 5123, 5124, 5125, 5126, 5127, 5128, 5131, 5132, 5134, 5135, 5136, 5137, 5140, 5141, 5143, 5146, 5149, 5151, 5152, 5153, 5154, 5157, 5158, 5160, 5163, 5164, 5165, 5166, 5167, 5168, 5169, 5173, 5174, 5175, 5179, 5180, 5181, 5184, 5185, 5186, 5187, 5188, 5189, 5191, 5193, 5194, 5196, 5197, 5198, 5199, 5200, 5201, 5202, 5203, 5204, 5205, 5207, 5208, 5210, 5212, 5214, 5215, 5216, 5217, 5218, 5219, 5220, 5221, 5222, 5223, 5224, 5226, 5229, 5231, 5232, 5233, 5234, 5235, 5237, 5238, 5242, 5245, 5247, 5249, 5250, 5252, 5254, 5255, 5258, 5259, 5260, 5261, 5262, 5263, 5264, 5265, 5266, 5268, 5269, 5270, 5272, 5273, 5276, 5277, 5279, 5280, 5281, 5282, 5283, 5284, 5285, 5286, 5287, 5288, 5290, 5294, 5296, 5297, 5302, 5304, 5305, 5309, 5311, 5312, 5313, 5314, 5315, 5316, 5320, 5322, 5324, 5326, 5330, 5332, 5333, 5334, 5335, 5337, 5338, 5340, 5341, 5342, 5343, 5344, 5346, 5347, 5348, 5349, 5352, 5353, 5354, 5356, 5357, 5358, 5361, 5363, 5364, 5367, 5369, 5372, 5374, 5375, 5376, 5377, 5378, 5379, 5380, 5381, 5382, 5383, 5384, 5385, 5386, 5387, 5388, 5389, 5390, 5391, 5392, 5393, 5394, 5395, 5398, 5399, 5400, 5401, 5402, 5406, 5408, 5409, 5410, 5411, 5412, 5413, 5414, 5416, 5417, 5418, 5419, 5420, 5421, 5422, 5423, 5424, 5425, 5427, 5428, 5429, 5430, 5431, 5433, 5434, 5435, 5436, 5437, 5439, 5442, 5443, 5444, 5445, 5446, 5447, 5448, 5449, 5450, 5454, 5457, 5458, 5459, 5460, 5462, 5464, 5466, 5467, 5469, 5470, 5473, 5474, 5475, 5476, 5477, 5478, 5481, 5482, 5484, 5486, 5488, 5489, 5490, 5491, 5492, 5495, 5496, 5497, 5498, 5499, 5500, 5501, 5502, 5504, 5505, 5506, 5507, 5509, 5510, 5512, 5513, 5515, 5516, 5517, 5518, 5521, 5522, 5523, 5524, 5525, 5526, 5527, 5528, 5529, 5530, 5531, 5532, 5534, 5535, 5536, 5537, 5538, 5539, 5540, 5542, 5543, 5544, 5545, 5546, 5547, 5548, 5549, 5550, 5551, 5552, 5553, 5556, 5557, 5558, 5561, 5564, 5565, 5568, 5569, 5572, 5575, 5577, 5578, 5579, 5580, 5581, 5582, 5583, 5584, 5585, 5586, 5589, 5590, 5591, 5592, 5593, 5594, 5597, 5598, 5599, 5600, 5602, 5607, 5610, 5611, 5612, 5614, 5616, 5617, 5618, 5622, 5624, 5626, 5627, 5628, 5629, 5630, 5631, 5632, 5636, 5637, 5639, 5640, 5641, 5643, 5645, 5648, 5649, 5650, 5651, 5652, 5653, 5654, 5656, 5657, 5658, 5660, 5661, 5663, 5664, 5666, 5667, 5670, 5672, 5674, 5675, 5676, 5677, 5679, 5680, 5681, 5682, 5683, 5684, 5686, 5688, 5690, 5692, 5693, 5694, 5695, 5696, 5697, 5699, 5700, 5702, 5706, 5707, 5710, 5713, 5714, 5715, 5717, 5718, 5719, 5720, 5721, 5722, 5723, 5724, 5726, 5727, 5728, 5729, 5732, 5733, 5734, 5735, 5737, 5738, 5739, 5742, 5743, 5745, 5748, 5749, 5750, 5751, 5753, 5756, 5757, 5759, 5760, 5762, 5764, 5765, 5767, 5768, 5770, 5772, 5774, 5776, 5777, 5778, 5779, 5780, 5781, 5783, 5786, 5787, 5788, 5791, 5792, 5794, 5795, 5796, 5797, 5798, 5799, 5800, 5802, 5803, 5804, 5808, 5809, 5811, 5812, 5813, 5814, 5815, 5816, 5817, 5818, 5819, 5820, 5822, 5823, 5825, 5826, 5828, 5829, 5830, 5832, 5833, 5834, 5835, 5836, 5841, 5842, 5843, 5844, 5845, 5846, 5847, 5849, 5850, 5851, 5852, 5853, 5854, 5856, 5857, 5858, 5859, 5861, 5862, 5863, 5865, 5866, 5868, 5869, 5870, 5871, 5875, 5876, 5877, 5879, 5882, 5883, 5884, 5885, 5889, 5892, 5893, 5895, 5896, 5897, 5900, 5901, 5903, 5904, 5905, 5907, 5908, 5910, 5911, 5915, 5916, 5917, 5918, 5920, 5921, 5922, 5923, 5924, 5925, 5926, 5927, 5930, 5931, 5932, 5933, 5934, 5935, 5937, 5938, 5940, 5941, 5942, 5943, 5944, 5945, 5949, 5953, 5954, 5955, 5957, 5958, 5959, 5960, 5963, 5964, 5968, 5969, 5970, 5971, 5973, 5974, 5976, 5983, 5984, 5985, 5986, 5988, 5991, 5992, 5994, 5995, 5996, 5997, 6000, 6001, 6002, 6003, 6004, 6006, 6007, 6008, 6010, 6011, 6012, 6013, 6014, 6015, 6017, 6018, 6019, 6020, 6022, 6023, 6027, 6029, 6030, 6032, 6035, 6036, 6039, 6041, 6043, 6044, 6047, 6049, 6051, 6052, 6053, 6055, 6056, 6057, 6058, 6059, 6060, 6061, 6062, 6063, 6064, 6065, 6066, 6068, 6074, 6079, 6080, 6081, 6082, 6083, 6084, 6086, 6087, 6089, 6093, 6094, 6095, 6096, 6097, 6099, 6100, 6101, 6102, 6103, 6104, 6105, 6106, 6107, 6108, 6109, 6110, 6111, 6113, 6114, 6115, 6116, 6117, 6118, 6119, 6120, 6121, 6122, 6123, 6124, 6125, 6126, 6127, 6128, 6129, 6130, 6131, 6132, 6134, 6135, 6137, 6138, 6146, 6149, 6150, 6153, 6155, 6156, 6157, 6158, 6159, 6160, 6161, 6162, 6163, 6164, 6165, 6166, 6167, 6168, 6169, 6170, 6171, 6172, 6174, 6176, 6177, 6178, 6179, 6180, 6181, 6183, 6184, 6185, 6189, 6190, 6192, 6193, 6195, 6196, 6197, 6199, 6200, 6203, 6204, 6205, 6206, 6207, 6208, 6209, 6210, 6211, 6212, 6214, 6215, 6216, 6217, 6220, 6221, 6223, 6224, 6225, 6226, 6228, 6230, 6232, 6233, 6234, 6235, 6236, 6238, 6240, 6241, 6242, 6243, 6244, 6246, 6249, 6250, 6251, 6252, 6255, 6257, 6260, 6261, 6262, 6265, 6266, 6268, 6269, 6273, 6274, 6275, 6276, 6277, 6278, 6279, 6280, 6282, 6284, 6285, 6286, 6288, 6291, 6292, 6293, 6295, 6296, 6299, 6300, 6302, 6303, 6304, 6308, 6310, 6311, 6312, 6313, 6314, 6315, 6316, 6317, 6320, 6321, 6322, 6323, 6324, 6328, 6329, 6333, 6334, 6337, 6338, 6339, 6340, 6342, 6343, 6344, 6346, 6347, 6349, 6350, 6351, 6352, 6353, 6354, 6355, 6356, 6357, 6358, 6359, 6360, 6361, 6364, 6366, 6367, 6369, 6370, 6371, 6373, 6374, 6376, 6378, 6379, 6380, 6381, 6382, 6384, 6386, 6390, 6391, 6392, 6393, 6394, 6396, 6397, 6398, 6399, 6400, 6401, 6402, 6403, 6404, 6405, 6406, 6407, 6408, 6409, 6411, 6412, 6413, 6414, 6415, 6416, 6417, 6418, 6419, 6420, 6421, 6422, 6423, 6424, 6426, 6427, 6428, 6431, 6432, 6436, 6438, 6439, 6440, 6442, 6443, 6444, 6446, 6447, 6448, 6452, 6454, 6456, 6459, 6461, 6462, 6463, 6465, 6466, 6467, 6470, 6471, 6472, 6474, 6475, 6478, 6482, 6484, 6487, 6488, 6490, 6491, 6492, 6493, 6494, 6495, 6497, 6498, 6499, 6500, 6501, 6502, 6503, 6504, 6507, 6508, 6510, 6517, 6521, 6522, 6523, 6524, 6525, 6527, 6528, 6529, 6530, 6540, 6541, 6543, 6545, 6546, 6547, 6548, 6550, 6552, 6553, 6555, 6556, 6557, 6558, 6559, 6562, 6563, 6564, 6565, 6566, 6567, 6570, 6571, 6572, 6574, 6576, 6577, 6578, 6579, 6581, 6582, 6583, 6584, 6585, 6586, 6587, 6588, 6589, 6590, 6591, 6592, 6593, 6594, 6595, 6596, 6598, 6599, 6603, 6604, 6605, 6608, 6609, 6611, 6612, 6613, 6615, 6616, 6617, 6618, 6620, 6622, 6623, 6624, 6627, 6628, 6632, 6633, 6635, 6636, 6639, 6640, 6641, 6642, 6643, 6644, 6646, 6650, 6651, 6652, 6653, 6654, 6655, 6656, 6657, 6658, 6659, 6660, 6662, 6665, 6667, 6668, 6669, 6673, 6674, 6676, 6677, 6683, 6684, 6685, 6691, 6692, 6694, 6697, 6698, 6700, 6701, 6702, 6703, 6704, 6705, 6706, 6707, 6709, 6710, 6711, 6714, 6715, 6719, 6720, 6721, 6722, 6723, 6724, 6726, 6727, 6728, 6729, 6730, 6731, 6733, 6736, 6737, 6739, 6740, 6742, 6743, 6745, 6747, 6749, 6750, 6751, 6752, 6753, 6755, 6757, 6759, 6760, 6761, 6762, 6763, 6764, 6765, 6766, 6768, 6769, 6770, 6772, 6773, 6774, 6776, 6777, 6778, 6782, 6783, 6784, 6785, 6786, 6787, 6788, 6789, 6790, 6791, 6793, 6794, 6795, 6796, 6798, 6799, 6800, 6801, 6802, 6803, 6804, 6806, 6807, 6810, 6811, 6812, 6813, 6815, 6816, 6817, 6818, 6819, 6821, 6823, 6824, 6826, 6827, 6829, 6833, 6834, 6835, 6836, 6839, 6840, 6841, 6843, 6845, 6846, 6849, 6850, 6851, 6852, 6853, 6854, 6856, 6858, 6860, 6861, 6863, 6865, 6867, 6870, 6871, 6872, 6876, 6877, 6879, 6880, 6883, 6884, 6885, 6886, 6887, 6890, 6891, 6892, 6894, 6895, 6896, 6897, 6898, 6899, 6900, 6901, 6902, 6904, 6905, 6907, 6908, 6910, 6911, 6914, 6915, 6916, 6917, 6921, 6924, 6925, 6926, 6927, 6928, 6930, 6931, 6932, 6934, 6937, 6940, 6941, 6943, 6944, 6945, 6948, 6949, 6951, 6953, 6954, 6955, 6956, 6957, 6959, 6960, 6961, 6962, 6963, 6964, 6966, 6967, 6968, 6970, 6971, 6974, 6975, 6976, 6978, 6980, 6983, 6984, 6985, 6987, 6989, 6990, 6993, 6994, 6995, 6997, 7001, 7004, 7005, 7006, 7010, 7011, 7013, 7014, 7015, 7016, 7017, 7018, 7019, 7020, 7021, 7022, 7023, 7024, 7025, 7026, 7027, 7028, 7029, 7030, 7031, 7032, 7033, 7034, 7035, 7036, 7037, 7038, 7039, 7040, 7041, 7042, 7043, 7044, 7045, 7046, 7047, 7048, 7049, 7050, 7052, 7057, 7061, 7063, 7064, 7065, 7066, 7067, 7068, 7070, 7071, 7072, 7073, 7075, 7076, 7079, 7084, 7089, 7090, 7093, 7094, 7095, 7096, 7097, 7098, 7099, 7101, 7102, 7103, 7104, 7105, 7107, 7108, 7112, 7113, 7116, 7117, 7119, 7120, 7121, 7122, 7123, 7125, 7126, 7127, 7128, 7129, 7131, 7132, 7134, 7135, 7136, 7137, 7138, 7139, 7140, 7141, 7142, 7143, 7144, 7145, 7147, 7149, 7150, 7151, 7154, 7156, 7157, 7159, 7161, 7162, 7164, 7166, 7168, 7169, 7170, 7171, 7172, 7173, 7176, 7177, 7179, 7180, 7181, 7182, 7183, 7184, 7187, 7188, 7194, 7200, 7201, 7204, 7205, 7206, 7209, 7211, 7213, 7215, 7216, 7217, 7219, 7220, 7222, 7223, 7224, 7225, 7226, 7227, 7229, 7233, 7234, 7235, 7236, 7237, 7238, 7239, 7240, 7241, 7242, 7243, 7245, 7246, 7247, 7248, 7249, 7251, 7252, 7254, 7256, 7261, 7262, 7267, 7268, 7269, 7270, 7271, 7272, 7273, 7275, 7276, 7279, 7280, 7283, 7284, 7285, 7286, 7287, 7289, 7290, 7291, 7293, 7294, 7295, 7296, 7298, 7299, 7300, 7301, 7303, 7304, 7306, 7307, 7309, 7312, 7315, 7316, 7317, 7318, 7319, 7321, 7323, 7324, 7325, 7328, 7329, 7330, 7331, 7332, 7334, 7336, 7337, 7338, 7339, 7340, 7341, 7343, 7344, 7345, 7349, 7350, 7353, 7354, 7358, 7362, 7364, 7365, 7366, 7367, 7368, 7369, 7371, 7372, 7373, 7375, 7378, 7379, 7381, 7384, 7386, 7387, 7389, 7390, 7392, 7394, 7395, 7397, 7398, 7399, 7401, 7402, 7403, 7404, 7405, 7407, 7408, 7410, 7411, 7413, 7414, 7415, 7416, 7417, 7418, 7419, 7420, 7421, 7423, 7425, 7429, 7431, 7432, 7433, 7435, 7436, 7439, 7440, 7445, 7447, 7449, 7450, 7452, 7453, 7454, 7455, 7456, 7457, 7458, 7459, 7460, 7461, 7463, 7464, 7465, 7466, 7467, 7468, 7469, 7471, 7473, 7474, 7477, 7479, 7481, 7482, 7483, 7484, 7485, 7486, 7487, 7488, 7490, 7493, 7494, 7495, 7496, 7498, 7499, 7501, 7502, 7505, 7509, 7511, 7512, 7513, 7514, 7515, 7516, 7517, 7518, 7519, 7520, 7522, 7523, 7524, 7525, 7527, 7528, 7529, 7530, 7531, 7532, 7533, 7534, 7535, 7536, 7537, 7538, 7539, 7540, 7541, 7542, 7543, 7545, 7548, 7549, 7550, 7552, 7553, 7556, 7558, 7559, 7560, 7561, 7564, 7567, 7568, 7570, 7572, 7574, 7577, 7579, 7580, 7581, 7584, 7589, 7590, 7591, 7592, 7595, 7597, 7598, 7600, 7603, 7605, 7610, 7614, 7617, 7620, 7621, 7622, 7623, 7625, 7626, 7627, 7628, 7629, 7630, 7631, 7635, 7636, 7637, 7639, 7640, 7641, 7642, 7643, 7645, 7647, 7648, 7650, 7653, 7662, 7664, 7665, 7666, 7667, 7672, 7673, 7675, 7676, 7677, 7678, 7679, 7680, 7681, 7684, 7685, 7686, 7688, 7689, 7690, 7691, 7692, 7693, 7694, 7695, 7696, 7698, 7699, 7702, 7703, 7704, 7705, 7706, 7707, 7708, 7709, 7710, 7712, 7713, 7714, 7716, 7717, 7719, 7721, 7722, 7723, 7724, 7725, 7726, 7727, 7728, 7729, 7730, 7731, 7732, 7733, 7734, 7738, 7739, 7740, 7741, 7742, 7743, 7744, 7745, 7746, 7747, 7749, 7751, 7752, 7753, 7756, 7757, 7758, 7759, 7760, 7761, 7763, 7764, 7765, 7766, 7767, 7769, 7771, 7772, 7774, 7775, 7776, 7777, 7779, 7780, 7781, 7782, 7783, 7784, 7785, 7786, 7787, 7788, 7789, 7790, 7791, 7792, 7795, 7796, 7797, 7798, 7800, 7801, 7802, 7803, 7804, 7805, 7808, 7810, 7811, 7812, 7813, 7814, 7815, 7818, 7819, 7820, 7821, 7822, 7823, 7824, 7825, 7829, 7830, 7831, 7835, 7836, 7838, 7839, 7841, 7842, 7843, 7844, 7845, 7846, 7847, 7848, 7851, 7852, 7853, 7855, 7857, 7858, 7859, 7861, 7862, 7863, 7864, 7865, 7866, 7868, 7870, 7871, 7872, 7873, 7874, 7877, 7878, 7880, 7881, 7882, 7885, 7887, 7889, 7890, 7892, 7893, 7894, 7895, 7898, 7899, 7900, 7901, 7902, 7904, 7905, 7906, 7907, 7909, 7912, 7914, 7915, 7918, 7919, 7921, 7922, 7924, 7925, 7926, 7928, 7930, 7931, 7934, 7937, 7938, 7939, 7942, 7943, 7944, 7945, 7949, 7954, 7956, 7957, 7958, 7960, 7961, 7962, 7963, 7964, 7965, 7966, 7969, 7970, 7971, 7973, 7974, 7975, 7976, 7977, 7978, 7979, 7980, 7981, 7982, 7983, 7985, 7987, 7988, 7990, 7991, 7994, 7995, 8001, 8003, 8004, 8011, 8012, 8013, 8016, 8017, 8020, 8022, 8023, 8025, 8026, 8028, 8029, 8030, 8031, 8032, 8033, 8035, 8037, 8038, 8039, 8040, 8041, 8042, 8043, 8044, 8045, 8048, 8049, 8050, 8051, 8052, 8054, 8056, 8057, 8058, 8060, 8061, 8062, 8063, 8064, 8065, 8066, 8068, 8069, 8071, 8072, 8073, 8074, 8078, 8079, 8080, 8081, 8082, 8084, 8085, 8087, 8090, 8093, 8094, 8099, 8100, 8101, 8104, 8105, 8106, 8108, 8109, 8110, 8111, 8112, 8113, 8114, 8115, 8116, 8117, 8118, 8119, 8120, 8121, 8123, 8124, 8125, 8126, 8130, 8131, 8132, 8134, 8135, 8137, 8139, 8140, 8141, 8143, 8144, 8145, 8146, 8148, 8149, 8150, 8151, 8152, 8153, 8155, 8157, 8158, 8159, 8160, 8161, 8162, 8163, 8164, 8165, 8166, 8167, 8168, 8169, 8170, 8171, 8173, 8174, 8175, 8176, 8177, 8178, 8180, 8182, 8183, 8184, 8185, 8186, 8187, 8188, 8189, 8190, 8191, 8192, 8193, 8194, 8195, 8196, 8198, 8199, 8200, 8201, 8202, 8203, 8204, 8205, 8207, 8209, 8211, 8212, 8213, 8214, 8215, 8217, 8218, 8220, 8222, 8226, 8227, 8228, 8229, 8230, 8231, 8232, 8233, 8234, 8235, 8236, 8237, 8238, 8239, 8240, 8242, 8243, 8244, 8245, 8246, 8247, 8248, 8249, 8250, 8252, 8253, 8254, 8256, 8257, 8258, 8259, 8260, 8261, 8262, 8264, 8265, 8266, 8267, 8268, 8269, 8270, 8271, 8272, 8275, 8276, 8277, 8279, 8281, 8282, 8285, 8286, 8287, 8289, 8290, 8292, 8293, 8296, 8297, 8298, 8299, 8300, 8301, 8302, 8303, 8305, 8306, 8307, 8311, 8312, 8313, 8315, 8316, 8317, 8318, 8320, 8321, 8323, 8325, 8327, 8328, 8330, 8331, 8333, 8334, 8335, 8336, 8337, 8338, 8340, 8341, 8342, 8344, 8345, 8346, 8348, 8349, 8350, 8351, 8352, 8353, 8354, 8355, 8356, 8357, 8358, 8359, 8360, 8361, 8362, 8364, 8365, 8366, 8368, 8369, 8370, 8371, 8372, 8373, 8374, 8375, 8376, 8377, 8378, 8379, 8380, 8381, 8382, 8383, 8384, 8388, 8390, 8391, 8392, 8394, 8395, 8398, 8399, 8400, 8402, 8403, 8405, 8411, 8413, 8414, 8417, 8420, 8422, 8424, 8430, 8431, 8432, 8433, 8434, 8436, 8437, 8438, 8439, 8441, 8443, 8444, 8445, 8448, 8449, 8451, 8454, 8455, 8457, 8458, 8460, 8462, 8464, 8465, 8466, 8467, 8468, 8469, 8470, 8471, 8472, 8473, 8474, 8475, 8477, 8478, 8479, 8480, 8481, 8483, 8484, 8485, 8486, 8487, 8488, 8490, 8491, 8492, 8494, 8495, 8496, 8497, 8498, 8500, 8501, 8503, 8504, 8505, 8506, 8507, 8510, 8511, 8513, 8514, 8522, 8523, 8524, 8525, 8526, 8527, 8528, 8531, 8533, 8534, 8536, 8537, 8538, 8539, 8541, 8542, 8544, 8545, 8546, 8547, 8549, 8550, 8552, 8554, 8556, 8557, 8558, 8559, 8563, 8564, 8565, 8567, 8568, 8569, 8570, 8571, 8573, 8574, 8576, 8577, 8579, 8580, 8581, 8582, 8585, 8586, 8589, 8592, 8595, 8596, 8599, 8600, 8601, 8602, 8603, 8605, 8607, 8608, 8609, 8610, 8611, 8613, 8615, 8617, 8618, 8619, 8622, 8623, 8624, 8627, 8628, 8629, 8630, 8634, 8635, 8636, 8638, 8639, 8641, 8642, 8643, 8644, 8645, 8646, 8651, 8652, 8654, 8655, 8656, 8657, 8659, 8660, 8662, 8663, 8664, 8665, 8666, 8669, 8673, 8674, 8675, 8676, 8678, 8679, 8681, 8682, 8683, 8684, 8688, 8690, 8694, 8701, 8703, 8706, 8709, 8711, 8714, 8715, 8716, 8717, 8718, 8720, 8721, 8722, 8723, 8724, 8726, 8727, 8728, 8729, 8730, 8731, 8732, 8734, 8735, 8737, 8741, 8742, 8743, 8747, 8748, 8751, 8752, 8753, 8754, 8755, 8757, 8758, 8760, 8761, 8764, 8765, 8766, 8767, 8768, 8769, 8770, 8772, 8773, 8774, 8777, 8779, 8781, 8782, 8784, 8786, 8788, 8789, 8790, 8792, 8794, 8795, 8798, 8799, 8800, 8806, 8807, 8808, 8813, 8814, 8815, 8816, 8817, 8818, 8821, 8824, 8825, 8826, 8828, 8829, 8831, 8832, 8833, 8835, 8836, 8837, 8840, 8841, 8842, 8844, 8845, 8846, 8847, 8849, 8851, 8852, 8854, 8856, 8857, 8858, 8860, 8861, 8862, 8865, 8866, 8867, 8869, 8870, 8871, 8873, 8874, 8875, 8876, 8879, 8880, 8881, 8882, 8884, 8885, 8893, 8896, 8897, 8898, 8901, 8902, 8904, 8907, 8908, 8909, 8910, 8912, 8913, 8914, 8915, 8916, 8917, 8918, 8919, 8921, 8922, 8923, 8924, 8925, 8927, 8928, 8929, 8930, 8932, 8933, 8934, 8935, 8937, 8938, 8939, 8942, 8943, 8945, 8946, 8948, 8949, 8950, 8951, 8953, 8954, 8956, 8959, 8960, 8961, 8962, 8964, 8966, 8967, 8968, 8969, 8971, 8974, 8975, 8977, 8978, 8979, 8981, 8984, 8985, 8989, 8990, 8991, 8994, 8995, 8996, 8998, 8999, 9004, 9005, 9007, 9008, 9009, 9010, 9011, 9012, 9015, 9018, 9021, 9022, 9024, 9026, 9029, 9030, 9031, 9035, 9036, 9037, 9039, 9041, 9046, 9048, 9049, 9050, 9051, 9052, 9053, 9054, 9058, 9059, 9061, 9063, 9065, 9066, 9069, 9070, 9071, 9073, 9074, 9076, 9077, 9081, 9085, 9086, 9088, 9089, 9090, 9091, 9093, 9094, 9095, 9096, 9099, 9100, 9103, 9105, 9107, 9110, 9111, 9112, 9113, 9115, 9119, 9120, 9121, 9122, 9123, 9124, 9126, 9127, 9128, 9129, 9130, 9131, 9132, 9134, 9135, 9139, 9140, 9141, 9142, 9143, 9145, 9147, 9148, 9153, 9154, 9155, 9156, 9159, 9166, 9171, 9176, 9180, 9181, 9183, 9186, 9187, 9188, 9189, 9190, 9191, 9193, 9195, 9196, 9197, 9199, 9200, 9201, 9202, 9203, 9205, 9208, 9209, 9210, 9211, 9213, 9215, 9217, 9218, 9220, 9225, 9226, 9228, 9229, 9230, 9231, 9232, 9236, 9237, 9239, 9240, 9241, 9244, 9248, 9249, 9250, 9251, 9252, 9254, 9255, 9257, 9258, 9259, 9260, 9261, 9262, 9263, 9264, 9269, 9270, 9271, 9273, 9274, 9276, 9278, 9279, 9281, 9282, 9283, 9284, 9285, 9287, 9288, 9289, 9290, 9291, 9292, 9296, 9297, 9298, 9299, 9301, 9302, 9303, 9304, 9305, 9307, 9308, 9309, 9310, 9311, 9312, 9314, 9316, 9318, 9320, 9321, 9322, 9323, 9324, 9326, 9328, 9330, 9331, 9332, 9333, 9334, 9335, 9337, 9338, 9343, 9344, 9345, 9346, 9349, 9350, 9352, 9353, 9354, 9356, 9357, 9358, 9362, 9363, 9365, 9366, 9367, 9368, 9371, 9372, 9373, 9375, 9377, 9378, 9381, 9382, 9383, 9384, 9385, 9386, 9387, 9389, 9391, 9392, 9393, 9394, 9395, 9396, 9397, 9398, 9399, 9403, 9404, 9405, 9407, 9408, 9409, 9410, 9411, 9413, 9414, 9417, 9418, 9419, 9420, 9421, 9423, 9426, 9427, 9429, 9430, 9431, 9433, 9434, 9435, 9437, 9438, 9439, 9440, 9441, 9444, 9445, 9448, 9450, 9452, 9453, 9454, 9456, 9457, 9458, 9459, 9461, 9462, 9463, 9464, 9465, 9467, 9468, 9469, 9470, 9471, 9472, 9474, 9475, 9477, 9478, 9479, 9480, 9481, 9483, 9486, 9487, 9488, 9491, 9493, 9495, 9497, 9498, 9499, 9501, 9503, 9504, 9505, 9506, 9507, 9508, 9509, 9510, 9511, 9512, 9513, 9514, 9515, 9517, 9518, 9519, 9520, 9521, 9522, 9523, 9525, 9526, 9527, 9528, 9531, 9532, 9533, 9534, 9536, 9538, 9539, 9540, 9541, 9542, 9543, 9545, 9546, 9550, 9551, 9552, 9553, 9554, 9555, 9557, 9558, 9559, 9561, 9563, 9564, 9565, 9567, 9568, 9569, 9570, 9571, 9572, 9573, 9574, 9575, 9576, 9577, 9578, 9579, 9580, 9581, 9582, 9583, 9584, 9585, 9586, 9588, 9590, 9591, 9592, 9593, 9594, 9596, 9597, 9598, 9599, 9600, 9602, 9603, 9604, 9606, 9607, 9611, 9612, 9613, 9616, 9617, 9618, 9620, 9621, 9623, 9624, 9628, 9629, 9630, 9631, 9632, 9633, 9634, 9636, 9637, 9639, 9640, 9641, 9642, 9645, 9647, 9648, 9649, 9650, 9652, 9653, 9654, 9655, 9656, 9657, 9658, 9659, 9660, 9661, 9662, 9663, 9664, 9665, 9667, 9668, 9669, 9670, 9672, 9673, 9674, 9676, 9677, 9679, 9680, 9684, 9687, 9688, 9689, 9690, 9691, 9695, 9696, 9698, 9700, 9701, 9703, 9704, 9705, 9706, 9707, 9708, 9711, 9715, 9716, 9718, 9720, 9726, 9728, 9729, 9735, 9743, 9744, 9747, 9750, 9751, 9753, 9757, 9760, 9763, 9768, 9771, 9772, 9774, 9775, 9776, 9780, 9781, 9782, 9786, 9787, 9789, 9790, 9791, 9792, 9793, 9794, 9795, 9796, 9797, 9798, 9799, 9800, 9803, 9804, 9805, 9807, 9809, 9811, 9813, 9814, 9815, 9819, 9820, 9821, 9823, 9827, 9829, 9830, 9832, 9834, 9835, 9837, 9838, 9839, 9840, 9841, 9842, 9844, 9846, 9848, 9852, 9853, 9854, 9855, 9857, 9861, 9862, 9864, 9866, 9867, 9868, 9872, 9873, 9874, 9875, 9876, 9879, 9881, 9883, 9885, 9887, 9888, 9890, 9891, 9893, 9894, 9895, 9898, 9899, 9900, 9901, 9902, 9903, 9905, 9906, 9908, 9909, 9911, 9913, 9914, 9915, 9916, 9917, 9918, 9919, 9920, 9923, 9924, 9925, 9926, 9927, 9928, 9929, 9930, 9931, 9932, 9933, 9935, 9936, 9937, 9938, 9939, 9940, 9942, 9947, 9949, 9950, 9952, 9953, 9954, 9956, 9958, 9959, 9963, 9969, 9970, 9971, 9972, 9973, 9974, 9975, 9980, 9981, 9982, 9983, 9984, 9985, 9986, 9987, 9988, 9989, 9991, 9993, 9996, 9997, 9998, 9999, 10000, 10001, 10002, 10003, 10004, 10005, 10006, 10007, 10008, 10009, 10010, 10011, 10013, 10014, 10017, 10018, 10019, 10020, 10022, 10023, 10024, 10025, 10030, 10031, 10032, 10035, 10036, 10037, 10038, 10040, 10046, 10048, 10049, 10050, 10051, 10052, 10053, 10058, 10060, 10061, 10062, 10063, 10065, 10066, 10067, 10068, 10069, 10070, 10071, 10072, 10073, 10074, 10075, 10076, 10077, 10078, 10080, 10081, 10083, 10084, 10085, 10086, 10087, 10090, 10092, 10093, 10094, 10096, 10097, 10098, 10099, 10100, 10101, 10103, 10105, 10106, 10107, 10109, 10111, 10112, 10113, 10115, 10116, 10118, 10119, 10120, 10121, 10123, 10125, 10126, 10127, 10128, 10129, 10130, 10131, 10133, 10135, 10137, 10138, 10139, 10141, 10144, 10145, 10146, 10147, 10148, 10149, 10152, 10156, 10157, 10159, 10160, 10161, 10163, 10164, 10165, 10166, 10168, 10170, 10172, 10173, 10174, 10177, 10179, 10181, 10182, 10183, 10184, 10186, 10188, 10191, 10193, 10194, 10196, 10198, 10199, 10200, 10201, 10202, 10204, 10205, 10206, 10207, 10209, 10210, 10211, 10213, 10214, 10215, 10216, 10218, 10220, 10221, 10223, 10224, 10225, 10226, 10227, 10228, 10229, 10230, 10231, 10232, 10233, 10234, 10235, 10236, 10238, 10239, 10240, 10241, 10242, 10243, 10244, 10246, 10248, 10249, 10250, 10251, 10252, 10254, 10256, 10257]\n"
     ]
    }
   ],
   "source": [
    "# Downsample rating=5 data to make it balance\n",
    "import random\n",
    "ind_5 = list(data.index[data['overall'] == 5])\n",
    "random.seed(0)\n",
    "random.shuffle(ind_5)\n",
    "\n",
    "data.drop(labels=None, axis=0, index=ind_5[: int(round(len(ind_5) / 3 * 1, 0))], columns=None, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_3 = list(data.index[data['overall'] == 3])\n",
    "random.seed(1)\n",
    "random.shuffle(ind_3)\n",
    "\n",
    "data.drop(labels=None, axis=0, index=ind_3[: int(round(len(ind_3) / 3 * 1, 0))], columns=None, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([3524.,    0., 3774.,    0.,    0., 4645.,    0., 3831.,    0.,\n",
       "        4621.]),\n",
       " array([1. , 1.4, 1.8, 2.2, 2.6, 3. , 3.4, 3.8, 4.2, 4.6, 5. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.title('Total Rating')\n",
    "plt.hist(data['overall'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 rows in reviews: \n",
      " [\"Not much to write about here, but it does exactly what it's supposed to. filters out the pop sounds. now my recordings are much more crisp. it is one of the lowest prices pop filters on amazon so might as well buy it, they honestly work the same despite their pricing,\"\n",
      " \"The product does exactly as it should and is quite affordable.I did not realized it was double screened until it arrived, so it was even better than I had expected.As an added bonus, one of the screens carries a small hint of the smell of an old grape candy I used to buy, so for reminiscent's sake, I cannot stop putting the pop filter next to my nose and smelling it after recording. :DIf you needed a pop filter, this will work just as well as the expensive ones, and it may even come with a pleasing aroma like mine did!Buy this product! :]\"\n",
      " 'The primary job of this device is to block the breath that would otherwise produce a popping sound, while allowing your voice to pass through with no noticeable reduction of volume or high frequencies. The double cloth filter blocks the pops and lets the voice through with no coloration. The metal clamp mount attaches to the mike stand secure enough to keep it attached. The goose neck needs a little coaxing to stay where you put it.'\n",
      " 'Nice windscreen protects my MXL mic and prevents pops. Only thing is that the gooseneck is only marginally able to hold the screen in position and requires careful positioning of the clamp to avoid sagging.'\n",
      " \"This pop filter is great. It looks and performs like a studio filter. If you're recording vocals this will eliminate the pops that gets recorded when you sing.\"] \n",
      "\n",
      "First 5 rows in rating: \n",
      " [5 5 5 5 5] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "review = np.array(data['reviewText'])\n",
    "rating = np.array(data['overall'])\n",
    "\n",
    "print(\"First 5 rows in reviews: \\n\", review[:5], \"\\n\")\n",
    "print(\"First 5 rows in rating: \\n\", rating[:5], \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define k-fold validation\n",
    "def k_fold_val_score(model, x, y, fold=5, seed=0):\n",
    "    \"\"\"\n",
    "    function: calculate the performance based on k-fold cross validation score\n",
    "    param-model: model class input for k-fold validation\n",
    "    param-x, y: features and labels, should be np\n",
    "    param-fold: number of k in k-fold cross validation\n",
    "    param-seed: random seed used in split k-fold\n",
    "    \"\"\"\n",
    "    ind = [i for i in range(len(x))]\n",
    "    subset_size = len(ind) // fold\n",
    "    # shuffle data\n",
    "    random.seed(seed)\n",
    "    random.shuffle(ind)\n",
    "    cur_ind_loc = 0\n",
    "    accuracy = list()\n",
    "    auc_score = list()\n",
    "    # get accuracy of cross-validation\n",
    "    for fold_ind in range(fold):\n",
    "        if fold_ind == fold - 1:\n",
    "            end_ind_loc = len(ind) - 1\n",
    "        else:\n",
    "            end_ind_loc = cur_ind_loc + subset_size\n",
    "        X_val = x[ind[cur_ind_loc: end_ind_loc]]\n",
    "        y_val = y[ind[cur_ind_loc: end_ind_loc]]\n",
    "        X_train = np.vstack([x[ind[0:cur_ind_loc]], x[ind[end_ind_loc:]]])\n",
    "        y_train = np.hstack([y[ind[0:cur_ind_loc]], y[ind[end_ind_loc:]]])  # y.shape=(n,), so use hstack\n",
    "        # train the model and predict validation\n",
    "        md_instance = model\n",
    "        md = md_instance.fit(X_train, y_train)\n",
    "        y_pred = md.predict(X_val)\n",
    "        # y_pred_prob = md.predict_proba(X_val)\n",
    "        # record the accuracy and auc_score\n",
    "        accuracy.append(np.mean(y_val == y_pred))\n",
    "        # auc_score.append(metrics.roc_auc_score(y_val, y_pred_prob[:, 1]))\n",
    "\n",
    "        cur_ind_loc += subset_size\n",
    "    return round(np.mean(np.array(accuracy)), 3)  # round(np.mean(np.array(auc_score)), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split train, validation and test dataset at a ratio of 6:2:2\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split train and test\n",
    "review_train, review_test, rating_train, rating_test = \\\n",
    "train_test_split(review, rating, test_size=0.1, shuffle=True, stratify=rating, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18355\n",
      "2040\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Description Analysis\n",
    "print(len(review_train))\n",
    "print(len(review_test))\n",
    "\n",
    "plt.figure()\n",
    "ax1 = plt.subplot(2, 2, 1, frameon = False)\n",
    "plt.title('Training Rating')\n",
    "plt.hist(rating_train)\n",
    "\n",
    "ax2 = plt.subplot(2, 2, 2, frameon = False)\n",
    "plt.title('Test Rating')\n",
    "plt.hist(rating_test)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Supervised Model for text mining\n",
    "#### *All the hyperparameters are the best according to k-fold validation grid-search. Due to length of the code, it is run on our own pannel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the word\n",
    "normalized_train_reviews = normalize_corpus(review_train)\n",
    "normalized_test_reviews = normalize_corpus(review_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Different algorithm to train the model based on Word Bag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word Bag\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer_BOW = CountVectorizer(max_features=1000)\n",
    "feature_matrix_TRAIN_BOW = vectorizer_BOW.fit_transform(normalized_train_reviews).astype(float)\n",
    "feature_matrix_TEST_BOW = vectorizer_BOW.transform(normalized_test_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy rate: 0.632\n"
     ]
    }
   ],
   "source": [
    "# Using poly_svc\n",
    "svc_poly = SVC(C=0.8, kernel='poly', degree=1)\n",
    "svc_poly.fit(feature_matrix_TRAIN_BOW, rating_train)\n",
    "\n",
    "predicted_svc_poly = svc_poly.predict(feature_matrix_TEST_BOW) \n",
    "print('Accuracy rate:', np.round(np.mean(predicted_svc_poly == rating_test), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy rate: 0.807\n"
     ]
    }
   ],
   "source": [
    "# Using rbf_svc\n",
    "svc_rbf = SVC(C=1.4, kernel='rbf', gamma=0.02)\n",
    "svc_rbf.fit(feature_matrix_TRAIN_BOW, rating_train)\n",
    "\n",
    "predicted_svc_rbf = svc_rbf.predict(feature_matrix_TEST_BOW)\n",
    "print('Accuracy rate:', np.round(np.mean(predicted_svc_rbf == rating_test), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy rate: 0.86\n"
     ]
    }
   ],
   "source": [
    "# Using Random_Forest\n",
    "forest = RandomForestClassifier(n_estimators=100, max_depth=None, oob_score=True, random_state=42)\n",
    "forest.fit(feature_matrix_TRAIN_BOW, rating_train)\n",
    "\n",
    "predicted_forest = forest.predict(feature_matrix_TEST_BOW)\n",
    "print('Accuracy rate:', np.round(np.mean(predicted_forest == rating_test), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy rate: 0.658\n"
     ]
    }
   ],
   "source": [
    "# Using Decision Tree\n",
    "tree = DecisionTreeClassifier(criterion='gini', splitter='best', max_depth=None, min_samples_split=2,\n",
    "                                min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features=None,\n",
    "                                random_state=None, max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
    "                                min_impurity_split=None, class_weight=None)\n",
    "tree.fit(feature_matrix_TRAIN_BOW, rating_train)\n",
    "\n",
    "predicted_tree = tree.predict(feature_matrix_TEST_BOW)\n",
    "print('Accuracy rate:', np.round(np.mean(predicted_tree == rating_test), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy rate: 0.728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Using ANN\n",
    "mlp = neural_network.MLPClassifier(hidden_layer_sizes=16, activation=\"relu\",\n",
    "                                   solver='adam', alpha=0.0003,\n",
    "                                   batch_size='auto', learning_rate=\"constant\",\n",
    "                                   learning_rate_init=0.001, power_t=0.5, max_iter=200, tol=1e-4)\n",
    "mlp.fit(feature_matrix_TRAIN_BOW, rating_train)\n",
    "\n",
    "predicted_mlp = mlp.predict(feature_matrix_TEST_BOW)\n",
    "print('Accuracy rate:', np.round(np.mean(predicted_mlp == rating_test), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Different algorithm to train the model based on TF-IDF + UniGram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF + UniGram\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer_TfUBgram = TfidfVectorizer(ngram_range = (1,1), norm = 'l2', smooth_idf = True) \n",
    "feature_matrix_TRAIN_TfUBgram = vectorizer_TfUBgram.fit_transform(normalized_train_reviews).astype(float)\n",
    "feature_matrix_TEST_TfUBgram = vectorizer_TfUBgram.transform(normalized_test_reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Have a look at the feature matrix with unigrams and bi-grams for the training data and note the n-grams:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>000s</th>\n",
       "      <th>000s worth</th>\n",
       "      <th>008ex</th>\n",
       "      <th>008ex great</th>\n",
       "      <th>008s</th>\n",
       "      <th>008s poll</th>\n",
       "      <th>009s</th>\n",
       "      <th>009s 008s</th>\n",
       "      <th>009s long</th>\n",
       "      <th>009s might</th>\n",
       "      <th>...</th>\n",
       "      <th>zylgiane</th>\n",
       "      <th>zylgiane damn</th>\n",
       "      <th>zylgic</th>\n",
       "      <th>zylgic damn</th>\n",
       "      <th>zylgically</th>\n",
       "      <th>zylgically use</th>\n",
       "      <th>zz</th>\n",
       "      <th>zz top</th>\n",
       "      <th>zzounds</th>\n",
       "      <th>zzounds musician</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 394599 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   000s  000s worth  008ex  008ex great  008s  008s poll  009s  009s 008s  \\\n",
       "0     0           0      0            0     0          0     0          0   \n",
       "1     0           0      0            0     0          0     0          0   \n",
       "2     0           0      0            0     0          0     0          0   \n",
       "3     0           0      0            0     0          0     0          0   \n",
       "4     0           0      0            0     0          0     0          0   \n",
       "\n",
       "   009s long  009s might  ...  zylgiane  zylgiane damn  zylgic  zylgic damn  \\\n",
       "0          0           0  ...         0              0       0            0   \n",
       "1          0           0  ...         0              0       0            0   \n",
       "2          0           0  ...         0              0       0            0   \n",
       "3          0           0  ...         0              0       0            0   \n",
       "4          0           0  ...         0              0       0            0   \n",
       "\n",
       "   zylgically  zylgically use  zz  zz top  zzounds  zzounds musician  \n",
       "0           0               0   0       0        0                 0  \n",
       "1           0               0   0       0        0                 0  \n",
       "2           0               0   0       0        0                 0  \n",
       "3           0               0   0       0        0                 0  \n",
       "4           0               0   0       0        0                 0  \n",
       "\n",
       "[5 rows x 394599 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_matrix_TRAIN_names = vectorizer_TfUBgram.get_feature_names() \n",
    "feature_matrix_TRAIN_table = pd.DataFrame(data = feature_matrix_TRAIN_TfUBgram.todense(), \n",
    "                                          columns = feature_matrix_TRAIN_names)\n",
    "feature_matrix_TRAIN_table.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy rate: 0.92\n"
     ]
    }
   ],
   "source": [
    "# Using poly_svc\n",
    "svc_poly = SVC(C=1.0, kernel='poly', degree=2)\n",
    "svc_poly.fit(feature_matrix_TRAIN_TfUBgram, rating_train)\n",
    "\n",
    "predicted_svc_poly = svc_poly.predict(feature_matrix_TEST_TfUBgram) \n",
    "print('Accuracy rate:', np.round(np.mean(predicted_svc_poly == rating_test), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "352\n",
      "347\n",
      "----------------------------------------------------------------------------\n",
      "378\n",
      "377\n",
      "----------------------------------------------------------------------------\n",
      "465\n",
      "457\n",
      "----------------------------------------------------------------------------\n",
      "383\n",
      "312\n",
      "----------------------------------------------------------------------------\n",
      "462\n",
      "547\n"
     ]
    }
   ],
   "source": [
    "print(np.sum(rating_test == 1))\n",
    "print(np.sum(predicted_svc_poly == 1))\n",
    "print(\"----------------------------------------------------------------------------\")\n",
    "print(np.sum(rating_test == 2))\n",
    "print(np.sum(predicted_svc_poly == 2))\n",
    "print(\"----------------------------------------------------------------------------\")\n",
    "print(np.sum(rating_test == 3))\n",
    "print(np.sum(predicted_svc_poly == 3))\n",
    "print(\"----------------------------------------------------------------------------\")\n",
    "print(np.sum(rating_test == 4))\n",
    "print(np.sum(predicted_svc_poly == 4))\n",
    "print(\"----------------------------------------------------------------------------\")\n",
    "print(np.sum(rating_test == 5))\n",
    "print(np.sum(predicted_svc_poly == 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy rate: 0.89\n"
     ]
    }
   ],
   "source": [
    "# Using rbf_svc\n",
    "svc_rbf = SVC(C=1.4, kernel='rbf', gamma=1)\n",
    "svc_rbf.fit(feature_matrix_TRAIN_TfUBgram, rating_train)\n",
    "\n",
    "predicted_svc_rbf = svc_rbf.predict(feature_matrix_TEST_TfUBgram)\n",
    "print('Accuracy rate:', np.round(np.mean(predicted_svc_rbf == rating_test), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "352\n",
      "350\n",
      "----------------------------------------------------------------------------\n",
      "378\n",
      "379\n",
      "----------------------------------------------------------------------------\n",
      "465\n",
      "474\n",
      "----------------------------------------------------------------------------\n",
      "383\n",
      "352\n",
      "----------------------------------------------------------------------------\n",
      "462\n",
      "485\n"
     ]
    }
   ],
   "source": [
    "print(np.sum(rating_test == 1))\n",
    "print(np.sum(predicted_svc_rbf == 1))\n",
    "print(\"----------------------------------------------------------------------------\")\n",
    "print(np.sum(rating_test == 2))\n",
    "print(np.sum(predicted_svc_rbf == 2))\n",
    "print(\"----------------------------------------------------------------------------\")\n",
    "print(np.sum(rating_test == 3))\n",
    "print(np.sum(predicted_svc_rbf == 3))\n",
    "print(\"----------------------------------------------------------------------------\")\n",
    "print(np.sum(rating_test == 4))\n",
    "print(np.sum(predicted_svc_rbf == 4))\n",
    "print(\"----------------------------------------------------------------------------\")\n",
    "print(np.sum(rating_test == 5))\n",
    "print(np.sum(predicted_svc_rbf == 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy rate: 0.871\n"
     ]
    }
   ],
   "source": [
    "# Using Random_Forest\n",
    "forest = RandomForestClassifier(n_estimators=50, max_depth=None, oob_score=True, random_state=42)\n",
    "forest.fit(feature_matrix_TRAIN_TfUBgram, rating_train)\n",
    "\n",
    "predicted_forest = forest.predict(feature_matrix_TEST_TfUBgram)\n",
    "print('Accuracy rate:', np.round(np.mean(predicted_forest == rating_test), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "352\n",
      "349\n",
      "----------------------------------------------------------------------------\n",
      "378\n",
      "378\n",
      "----------------------------------------------------------------------------\n",
      "465\n",
      "505\n",
      "----------------------------------------------------------------------------\n",
      "383\n",
      "294\n",
      "----------------------------------------------------------------------------\n",
      "462\n",
      "514\n"
     ]
    }
   ],
   "source": [
    "print(np.sum(rating_test == 1))\n",
    "print(np.sum(predicted_forest == 1))\n",
    "print(\"----------------------------------------------------------------------------\")\n",
    "print(np.sum(rating_test == 2))\n",
    "print(np.sum(predicted_forest == 2))\n",
    "print(\"----------------------------------------------------------------------------\")\n",
    "print(np.sum(rating_test == 3))\n",
    "print(np.sum(predicted_forest == 3))\n",
    "print(\"----------------------------------------------------------------------------\")\n",
    "print(np.sum(rating_test == 4))\n",
    "print(np.sum(predicted_forest == 4))\n",
    "print(\"----------------------------------------------------------------------------\")\n",
    "print(np.sum(rating_test == 5))\n",
    "print(np.sum(predicted_forest == 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy rate: 0.636\n"
     ]
    }
   ],
   "source": [
    "# Using Decision Tree\n",
    "tree = DecisionTreeClassifier(criterion='gini', splitter='best', max_depth=None, min_samples_split=2,\n",
    "                                min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features=None,\n",
    "                                random_state=None, max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
    "                                min_impurity_split=None, class_weight=None)\n",
    "tree.fit(feature_matrix_TRAIN_TfUBgram, rating_train)\n",
    "\n",
    "predicted_tree = tree.predict(feature_matrix_TEST_TfUBgram)\n",
    "print('Accuracy rate:', np.round(np.mean(predicted_tree == rating_test), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "352\n",
      "379\n",
      "----------------------------------------------------------------------------\n",
      "378\n",
      "396\n",
      "----------------------------------------------------------------------------\n",
      "465\n",
      "450\n",
      "----------------------------------------------------------------------------\n",
      "383\n",
      "385\n",
      "----------------------------------------------------------------------------\n",
      "462\n",
      "430\n"
     ]
    }
   ],
   "source": [
    "print(np.sum(rating_test == 1))\n",
    "print(np.sum(predicted_tree == 1))\n",
    "print(\"----------------------------------------------------------------------------\")\n",
    "print(np.sum(rating_test == 2))\n",
    "print(np.sum(predicted_tree == 2))\n",
    "print(\"----------------------------------------------------------------------------\")\n",
    "print(np.sum(rating_test == 3))\n",
    "print(np.sum(predicted_tree == 3))\n",
    "print(\"----------------------------------------------------------------------------\")\n",
    "print(np.sum(rating_test == 4))\n",
    "print(np.sum(predicted_tree == 4))\n",
    "print(\"----------------------------------------------------------------------------\")\n",
    "print(np.sum(rating_test == 5))\n",
    "print(np.sum(predicted_tree == 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy rate: 0.794\n"
     ]
    }
   ],
   "source": [
    "# Using ANN\n",
    "mlp = neural_network.MLPClassifier(hidden_layer_sizes=16, activation=\"relu\",\n",
    "                                   solver='adam', alpha=0.0003,\n",
    "                                   batch_size='auto', learning_rate=\"constant\",\n",
    "                                   learning_rate_init=0.001, power_t=0.5, max_iter=200, tol=1e-4)\n",
    "mlp.fit(feature_matrix_TRAIN_TfUBgram, rating_train)\n",
    "\n",
    "predicted_mlp = mlp.predict(feature_matrix_TEST_TfUBgram)\n",
    "print('Accuracy rate:', np.round(np.mean(predicted_mlp == rating_test), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "352\n",
      "348\n",
      "----------------------------------------------------------------------------\n",
      "378\n",
      "384\n",
      "----------------------------------------------------------------------------\n",
      "465\n",
      "471\n",
      "----------------------------------------------------------------------------\n",
      "383\n",
      "408\n",
      "----------------------------------------------------------------------------\n",
      "462\n",
      "429\n"
     ]
    }
   ],
   "source": [
    "print(np.sum(rating_test == 1))\n",
    "print(np.sum(predicted_mlp == 1))\n",
    "print(\"----------------------------------------------------------------------------\")\n",
    "print(np.sum(rating_test == 2))\n",
    "print(np.sum(predicted_mlp == 2))\n",
    "print(\"----------------------------------------------------------------------------\")\n",
    "print(np.sum(rating_test == 3))\n",
    "print(np.sum(predicted_mlp == 3))\n",
    "print(\"----------------------------------------------------------------------------\")\n",
    "print(np.sum(rating_test == 4))\n",
    "print(np.sum(predicted_mlp == 4))\n",
    "print(\"----------------------------------------------------------------------------\")\n",
    "print(np.sum(rating_test == 5))\n",
    "print(np.sum(predicted_mlp == 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Different algorithm to train the model based on TF-IDF + (Uni + Bi)Gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF + (Uni + Bi)Gram\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer_TfUBgram = TfidfVectorizer(ngram_range = (1,2), norm = 'l2', smooth_idf = True) \n",
    "feature_matrix_TRAIN_TfUBgram = vectorizer_TfUBgram.fit_transform(normalized_train_reviews).astype(float)\n",
    "feature_matrix_TEST_TfUBgram = vectorizer_TfUBgram.transform(normalized_test_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy rate: 0.916\n"
     ]
    }
   ],
   "source": [
    "# Using poly_svc\n",
    "svc_poly = SVC(C=1.0, kernel='poly', degree=2)\n",
    "svc_poly.fit(feature_matrix_TRAIN_TfUBgram, rating_train)\n",
    "\n",
    "predicted_svc_poly = svc_poly.predict(feature_matrix_TEST_TfUBgram) \n",
    "print('Accuracy rate:', np.round(np.mean(predicted_svc_poly == rating_test), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy rate: 0.903\n"
     ]
    }
   ],
   "source": [
    "# Using rbf_svc\n",
    "svc_rbf = SVC(C=1.4, kernel='rbf', gamma=1)\n",
    "svc_rbf.fit(feature_matrix_TRAIN_TfUBgram, rating_train)\n",
    "\n",
    "predicted_svc_rbf = svc_rbf.predict(feature_matrix_TEST_TfUBgram)\n",
    "print('Accuracy rate:', np.round(np.mean(predicted_svc_rbf == rating_test), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy rate: 0.874\n"
     ]
    }
   ],
   "source": [
    "# Using Random_Forest\n",
    "forest = RandomForestClassifier(n_estimators=50, max_depth=None, oob_score=True, random_state=42)\n",
    "forest.fit(feature_matrix_TRAIN_TfUBgram, rating_train)\n",
    "\n",
    "predicted_forest = forest.predict(feature_matrix_TEST_TfUBgram)\n",
    "print('Accuracy rate:', np.round(np.mean(predicted_forest == rating_test), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy rate: 0.64\n"
     ]
    }
   ],
   "source": [
    "# Using Decision Tree\n",
    "tree = DecisionTreeClassifier(criterion='gini', splitter='best', max_depth=None, min_samples_split=2,\n",
    "                                min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features=None,\n",
    "                                random_state=None, max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
    "                                min_impurity_split=None, class_weight=None)\n",
    "tree.fit(feature_matrix_TRAIN_TfUBgram, rating_train)\n",
    "\n",
    "predicted_tree = tree.predict(feature_matrix_TEST_TfUBgram)\n",
    "print('Accuracy rate:', np.round(np.mean(predicted_tree == rating_test), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy rate: 0.902\n"
     ]
    }
   ],
   "source": [
    "# Using ANN\n",
    "mlp = neural_network.MLPClassifier(hidden_layer_sizes=16, activation=\"relu\",\n",
    "                                   solver='adam', alpha=0.0003,\n",
    "                                   batch_size='auto', learning_rate=\"constant\",\n",
    "                                   learning_rate_init=0.001, power_t=0.5, max_iter=200, tol=1e-4)\n",
    "mlp.fit(feature_matrix_TRAIN_TfUBgram, rating_train)\n",
    "\n",
    "predicted_mlp = mlp.predict(feature_matrix_TEST_TfUBgram)\n",
    "print('Accuracy rate:', np.round(np.mean(predicted_mlp == rating_test), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Different algorithm to train the model based on TF-IDF + BiGram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF + BiGram\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer_TfUBgram = TfidfVectorizer(ngram_range = (2,2), norm = 'l2', smooth_idf = True) \n",
    "feature_matrix_TRAIN_TfUBgram = vectorizer_TfUBgram.fit_transform(normalized_train_reviews).astype(float)\n",
    "feature_matrix_TEST_TfUBgram = vectorizer_TfUBgram.transform(normalized_test_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy rate: 0.88\n"
     ]
    }
   ],
   "source": [
    "# Using poly_svc\n",
    "svc_poly = SVC(C=1.0, kernel='poly', degree=2)\n",
    "svc_poly.fit(feature_matrix_TRAIN_TfUBgram, rating_train)\n",
    "\n",
    "predicted_svc_poly = svc_poly.predict(feature_matrix_TEST_TfUBgram) \n",
    "print('Accuracy rate:', np.round(np.mean(predicted_svc_poly == rating_test), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy rate: 0.91\n"
     ]
    }
   ],
   "source": [
    "# Using rbf_svc\n",
    "svc_rbf = SVC(C=1.4, kernel='rbf', gamma=1)\n",
    "svc_rbf.fit(feature_matrix_TRAIN_TfUBgram, rating_train)\n",
    "\n",
    "predicted_svc_rbf = svc_rbf.predict(feature_matrix_TEST_TfUBgram)\n",
    "print('Accuracy rate:', np.round(np.mean(predicted_svc_rbf == rating_test), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy rate: 0.773\n"
     ]
    }
   ],
   "source": [
    "# Using Random_Forest\n",
    "forest = RandomForestClassifier(n_estimators=50, max_depth=None, oob_score=True, random_state=42)\n",
    "forest.fit(feature_matrix_TRAIN_TfUBgram, rating_train)\n",
    "\n",
    "predicted_forest = forest.predict(feature_matrix_TEST_TfUBgram)\n",
    "print('Accuracy rate:', np.round(np.mean(predicted_forest == rating_test), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy rate: 0.656\n"
     ]
    }
   ],
   "source": [
    "# Using Decision Tree\n",
    "tree = DecisionTreeClassifier(criterion='gini', splitter='best', max_depth=None, min_samples_split=2,\n",
    "                                min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features=None,\n",
    "                                random_state=None, max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
    "                                min_impurity_split=None, class_weight=None)\n",
    "tree.fit(feature_matrix_TRAIN_TfUBgram, rating_train)\n",
    "\n",
    "predicted_tree = tree.predict(feature_matrix_TEST_TfUBgram)\n",
    "print('Accuracy rate:', np.round(np.mean(predicted_tree == rating_test), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy rate: 0.899\n"
     ]
    }
   ],
   "source": [
    "# Using ANN\n",
    "mlp = neural_network.MLPClassifier(hidden_layer_sizes=16, activation=\"relu\",\n",
    "                                   solver='adam', alpha=0.0003,\n",
    "                                   batch_size='auto', learning_rate=\"constant\",\n",
    "                                   learning_rate_init=0.001, power_t=0.5, max_iter=200, tol=1e-4)\n",
    "mlp.fit(feature_matrix_TRAIN_TfUBgram, rating_train)\n",
    "\n",
    "predicted_mlp = mlp.predict(feature_matrix_TEST_TfUBgram)\n",
    "print('Accuracy rate:', np.round(np.mean(predicted_mlp == rating_test), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance Between Algorithms\n",
    "According to the result of previous model, create dataFrame recording token method, classifier and corresponding accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the accuracy data frame\n",
    "accuracy = pd.DataFrame({'Poly SVC': [0.632, 0.920, 0.916, 0.88],\n",
    "                         'Rbf SVC': [0.807, 0.890, 0.903, 0.910],\n",
    "                         'Random Forest': [0.860, 0.871, 0.874, 0.773],\n",
    "                         'Decision Tree': [0.658, 0.636, 0.64, 0.656],\n",
    "                         'ANN': [0.728, 0.794, 0.902, 0.899]}, \n",
    "                         index = ['Word Bag', 'TF-IDF UniGram', 'TF-IDF Uni+BiGram', 'TF-IDF BiGram'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "sns.heatmap(data=accuracy, cmap=sns.cubehelix_palette(as_cmap=True))\n",
    "plt.xlabel('Classifier')\n",
    "plt.ylabel('Tokenizer')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
